{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851af380-15ef-438e-ad51-04472348f1e6",
   "metadata": {},
   "source": [
    "### Step 1. 准备 Dataset + DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c4fa93-f636-4f5a-ac6b-92effa9dda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Twitter15Dataset(Dataset):\n",
    "    def __init__(self, graph_data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            graph_data_list (list): list of graphs, each graph is a dict {'x', 'edge_index', 'y'}\n",
    "        \"\"\"\n",
    "        self.graphs = graph_data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph = self.graphs[idx]\n",
    "        x = graph['x']  # (seq_len, feature_dim)\n",
    "        y = graph['y']  # int64 label (0~3)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "def collate_fn(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "\n",
    "    max_len = max(x.shape[0] for x in xs)  # find max sequence length in batch\n",
    "    feature_dim = xs[0].shape[1]\n",
    "\n",
    "    padded_xs = []\n",
    "    masks = []\n",
    "\n",
    "    for x in xs:\n",
    "        seq_len = x.shape[0]\n",
    "        pad_len = max_len - seq_len\n",
    "\n",
    "        if pad_len > 0:\n",
    "            pad = torch.zeros((pad_len, feature_dim), dtype=x.dtype)\n",
    "            x_padded = torch.cat([x, pad], dim=0)\n",
    "        else:\n",
    "            x_padded = x\n",
    "\n",
    "        mask = torch.cat([torch.ones(seq_len), torch.zeros(pad_len)]).bool()\n",
    "\n",
    "        padded_xs.append(x_padded)\n",
    "        masks.append(mask)\n",
    "\n",
    "    padded_xs = torch.stack(padded_xs)    # (batch_size, max_len, feature_dim)\n",
    "    masks = torch.stack(masks)             # (batch_size, max_len)\n",
    "    ys = torch.tensor(ys)                  # (batch_size,)\n",
    "\n",
    "    return padded_xs, masks, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d2a3f99-0e53-4ce0-b328-e5a32368170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1043, Val: 223, Test: 224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载你的清理版数据\n",
    "graph_data_list = torch.load(\"../processed/twitter15_graph_data_clean.pt\", weights_only=False)\n",
    "\n",
    "# 划分Train/Val/Test (7:1.5:1.5)\n",
    "train_graphs, temp_graphs = train_test_split(graph_data_list, test_size=0.3, random_state=42)\n",
    "val_graphs, test_graphs = train_test_split(temp_graphs, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_graphs)}, Val: {len(val_graphs)}, Test: {len(test_graphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1a066f7-510d-4732-bb5e-775da05f5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# 建Dataset\n",
    "train_dataset = Twitter15Dataset(train_graphs)\n",
    "val_dataset = Twitter15Dataset(val_graphs)\n",
    "test_dataset = Twitter15Dataset(test_graphs)\n",
    "\n",
    "# 建Dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b6a26-4e2c-4b7e-9e8d-fe2966327260",
   "metadata": {},
   "source": [
    "### Step 2: Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b613c42f-d68d-417c-ac2a-95ae85b3675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, num_classes, num_heads=8, num_layers=2, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        self.input_projection = nn.Linear(feature_dim, 768)  # 映射到768维\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=768,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        src_key_padding_mask = ~mask\n",
    "        x = self.input_projection(x)  # 加上这一行\n",
    "        transformer_out = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        pooled_output = transformer_out.mean(dim=1)\n",
    "\n",
    "        output = self.dropout(pooled_output)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, transformer_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690684a-800d-4030-b1eb-d77aef088022",
   "metadata": {},
   "source": [
    "### Step 3. 写训练和验证代码（Trainer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56735c89-d1ba-4314-8468-98f6df234351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for x, mask, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        x = torch.nan_to_num(x, nan=0.0)\n",
    "\n",
    "        # 不要 sum mask！直接传 mask！\n",
    "        logits, _ = model(x, mask)\n",
    "\n",
    "        loss = loss_fn(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        all_preds.extend(preds.detach().cpu().tolist())\n",
    "        all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "def evaluate_one_epoch(model, val_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, mask, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            x = torch.nan_to_num(x, nan=0.0)\n",
    "\n",
    "            logits, _ = model(x, mask)  # 注意这里直接传mask\n",
    "            logits = torch.clamp(logits, min=-10, max=10)\n",
    "\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_f1 = -float('inf')\n",
    "\n",
    "    def __call__(self, val_f1, model, save_path):\n",
    "        score = val_f1\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model, save_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_f1, model, save_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_f1, model, save_path):\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        self.best_f1 = val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a168a-6e41-461a-aa73-4a7014c0ec9c",
   "metadata": {},
   "source": [
    "### Step 4: 配置超参数 + 启动训练循环 (Runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ae78cff-6175-45b9-8539-2b5fb3d5ec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/home/xzhan/.conda/envs/env_214/lib/python3.13/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 1.3873 | Train Acc: 0.3557 | Train F1: 0.3545\n",
      "  Val   Loss: 1.3492 | Val   Acc: 0.2960 | Val   F1: 0.1640\n",
      "Epoch 2:\n",
      "  Train Loss: 1.1785 | Train Acc: 0.5014 | Train F1: 0.4958\n",
      "  Val   Loss: 1.3182 | Val   Acc: 0.3004 | Val   F1: 0.1620\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 3:\n",
      "  Train Loss: 1.0932 | Train Acc: 0.5781 | Train F1: 0.5721\n",
      "  Val   Loss: 1.2857 | Val   Acc: 0.4933 | Val   F1: 0.4708\n",
      "Epoch 4:\n",
      "  Train Loss: 0.9971 | Train Acc: 0.6520 | Train F1: 0.6484\n",
      "  Val   Loss: 1.2808 | Val   Acc: 0.4170 | Val   F1: 0.3521\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 5:\n",
      "  Train Loss: 0.9067 | Train Acc: 0.6855 | Train F1: 0.6833\n",
      "  Val   Loss: 1.3070 | Val   Acc: 0.3363 | Val   F1: 0.2311\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 6:\n",
      "  Train Loss: 0.8266 | Train Acc: 0.7555 | Train F1: 0.7541\n",
      "  Val   Loss: 1.2557 | Val   Acc: 0.4126 | Val   F1: 0.3503\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 7:\n",
      "  Train Loss: 0.7364 | Train Acc: 0.8102 | Train F1: 0.8087\n",
      "  Val   Loss: 1.2391 | Val   Acc: 0.4529 | Val   F1: 0.4114\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 8:\n",
      "  Train Loss: 0.6534 | Train Acc: 0.8600 | Train F1: 0.8584\n",
      "  Val   Loss: 1.2377 | Val   Acc: 0.4215 | Val   F1: 0.3733\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 9:\n",
      "  Train Loss: 0.5630 | Train Acc: 0.9195 | Train F1: 0.9189\n",
      "  Val   Loss: 1.2261 | Val   Acc: 0.4529 | Val   F1: 0.3988\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 10:\n",
      "  Train Loss: 0.4998 | Train Acc: 0.9559 | Train F1: 0.9557\n",
      "  Val   Loss: 1.2411 | Val   Acc: 0.5112 | Val   F1: 0.4736\n",
      "Epoch 11:\n",
      "  Train Loss: 0.4690 | Train Acc: 0.9799 | Train F1: 0.9797\n",
      "  Val   Loss: 1.2301 | Val   Acc: 0.4843 | Val   F1: 0.4388\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 12:\n",
      "  Train Loss: 0.4393 | Train Acc: 0.9875 | Train F1: 0.9876\n",
      "  Val   Loss: 1.2016 | Val   Acc: 0.4978 | Val   F1: 0.4635\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 13:\n",
      "  Train Loss: 0.4125 | Train Acc: 0.9971 | Train F1: 0.9971\n",
      "  Val   Loss: 1.2319 | Val   Acc: 0.4529 | Val   F1: 0.4190\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 14:\n",
      "  Train Loss: 0.4021 | Train Acc: 0.9971 | Train F1: 0.9971\n",
      "  Val   Loss: 1.2188 | Val   Acc: 0.5112 | Val   F1: 0.5017\n",
      "Epoch 15:\n",
      "  Train Loss: 0.3973 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: 1.2254 | Val   Acc: 0.4843 | Val   F1: 0.4631\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 16:\n",
      "  Train Loss: 0.3854 | Train Acc: 0.9990 | Train F1: 0.9991\n",
      "  Val   Loss: 1.2241 | Val   Acc: 0.5247 | Val   F1: 0.5133\n",
      "Epoch 17:\n",
      "  Train Loss: 0.3828 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2062 | Val   Acc: 0.5202 | Val   F1: 0.4944\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 18:\n",
      "  Train Loss: 0.3761 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2175 | Val   Acc: 0.5157 | Val   F1: 0.5073\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 19:\n",
      "  Train Loss: 0.3710 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2240 | Val   Acc: 0.5561 | Val   F1: 0.5476\n",
      "Epoch 20:\n",
      "  Train Loss: 0.3718 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2254 | Val   Acc: 0.5650 | Val   F1: 0.5537\n",
      "Epoch 21:\n",
      "  Train Loss: 0.3683 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2101 | Val   Acc: 0.5516 | Val   F1: 0.5456\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 22:\n",
      "  Train Loss: 0.3677 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2087 | Val   Acc: 0.5157 | Val   F1: 0.5027\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 23:\n",
      "  Train Loss: 0.3652 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.1959 | Val   Acc: 0.5426 | Val   F1: 0.5206\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 24:\n",
      "  Train Loss: 0.3620 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.1986 | Val   Acc: 0.5516 | Val   F1: 0.5410\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 25:\n",
      "  Train Loss: 0.3603 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2045 | Val   Acc: 0.6099 | Val   F1: 0.6016\n",
      "Epoch 26:\n",
      "  Train Loss: 0.3598 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2069 | Val   Acc: 0.5695 | Val   F1: 0.5621\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 27:\n",
      "  Train Loss: 0.3586 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2160 | Val   Acc: 0.5874 | Val   F1: 0.5793\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 28:\n",
      "  Train Loss: 0.3567 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2039 | Val   Acc: 0.5919 | Val   F1: 0.5857\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 29:\n",
      "  Train Loss: 0.3555 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2031 | Val   Acc: 0.5605 | Val   F1: 0.5496\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 30:\n",
      "  Train Loss: 0.3553 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.1948 | Val   Acc: 0.6009 | Val   F1: 0.5904\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 31:\n",
      "  Train Loss: 0.3547 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.1974 | Val   Acc: 0.5695 | Val   F1: 0.5598\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 32:\n",
      "  Train Loss: 0.3536 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.1974 | Val   Acc: 0.5874 | Val   F1: 0.5813\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 33:\n",
      "  Train Loss: 0.3534 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2073 | Val   Acc: 0.5740 | Val   F1: 0.5690\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 34:\n",
      "  Train Loss: 0.3530 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2034 | Val   Acc: 0.5695 | Val   F1: 0.5622\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 35:\n",
      "  Train Loss: 0.3528 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: 1.2055 | Val   Acc: 0.5785 | Val   F1: 0.5714\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping triggered!\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "save_path = os.path.abspath(\"../checkpoints/best_transformer_model.pt\")\n",
    "hidden_dim = 128\n",
    "num_classes = 4\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 1e-2\n",
    "max_epochs = 1000\n",
    "patience = 10\n",
    "\n",
    "# 模型\n",
    "feature_dim = 833 \n",
    "model = TransformerClassifier(\n",
    "    feature_dim=feature_dim,\n",
    "    hidden_dim=256,     # 可以调大一点，transformer内部FFN隐藏层\n",
    "    num_classes=4,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# 损失函数\n",
    "def smooth_cross_entropy(preds, targets, smoothing=0.1):\n",
    "    confidence = 1.0 - smoothing\n",
    "    logprobs = F.log_softmax(preds, dim=-1)\n",
    "    nll_loss = -logprobs.gather(dim=-1, index=targets.unsqueeze(1)).squeeze(1)\n",
    "    smooth_loss = -logprobs.mean(dim=-1)\n",
    "    loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "    return loss.mean()\n",
    "\n",
    "loss_fn = smooth_cross_entropy\n",
    "\n",
    "# Early Stopping\n",
    "early_stopper = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "# 开始训练\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss, val_acc, val_f1 = evaluate_one_epoch(model, val_loader, loss_fn, device)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f} | Val   F1: {val_f1:.4f}\")\n",
    "\n",
    "    early_stopper(val_f1, model, save_path)\n",
    "\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb2804e3-5af0-4c37-9aaa-fd23b05fe2ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "only bool and floating types of src_key_padding_mask are supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_loss, test_acc, test_f1\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# 调用测试函数\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m test_loss, test_acc, test_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Final Test Results ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 22\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, loss_fn, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnan_to_num(x, nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     21\u001b[0m lengths \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m---> 22\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(logits, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, y)\n",
      "File \u001b[0;32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[18], line 27\u001b[0m, in \u001b[0;36mTransformerClassifier.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m src_key_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mmask\n\u001b[1;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_projection(x)  \u001b[38;5;66;03m# 加上这一行\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m transformer_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m transformer_out\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/nn/modules/transformer.py:414\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    392\u001b[0m     src: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m     is_causal: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Pass the input through the encoder layers in turn.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m        see the docs in :class:`~torch.nn.Transformer`.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m     src_key_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_canonical_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc_key_padding_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_none_or_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m     mask \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39m_canonical_mask(\n\u001b[1;32m    423\u001b[0m         mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    424\u001b[0m         mask_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m         check_other\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    431\u001b[0m     output \u001b[38;5;241m=\u001b[39m src\n",
      "File \u001b[0;32m~/.conda/envs/env_214/lib/python3.13/site-packages/torch/nn/functional.py:5957\u001b[0m, in \u001b[0;36m_canonical_mask\u001b[0;34m(mask, mask_name, other_type, other_name, target_type, check_other)\u001b[0m\n\u001b[1;32m   5955\u001b[0m _mask_is_float \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_floating_point(mask)\n\u001b[1;32m   5956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _mask_dtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbool \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _mask_is_float:\n\u001b[0;32m-> 5957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   5958\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly bool and floating types of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5959\u001b[0m     )\n\u001b[1;32m   5960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_other \u001b[38;5;129;01mand\u001b[39;00m other_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _mask_dtype \u001b[38;5;241m!=\u001b[39m other_type:\n",
      "\u001b[0;31mAssertionError\u001b[0m: only bool and floating types of src_key_padding_mask are supported"
     ]
    }
   ],
   "source": [
    "# 加载训练好的最优模型\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Test阶段\n",
    "def test_model(model, test_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, mask, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            x = torch.nan_to_num(x, nan=0.0)\n",
    "\n",
    "            lengths = mask.sum(dim=1).cpu()\n",
    "            logits, _ = model(x, lengths)\n",
    "            logits = torch.clamp(logits, min=-10, max=10)\n",
    "\n",
    "            loss = loss_fn(logits, y)\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    test_acc = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return test_loss, test_acc, test_f1\n",
    "\n",
    "# 调用测试函数\n",
    "test_loss, test_acc, test_f1 = test_model(model, test_loader, loss_fn, device)\n",
    "\n",
    "print(\"=== Final Test Results ===\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7984a-7c2b-4904-bcde-492b327af2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "env_214"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
