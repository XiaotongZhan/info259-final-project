{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851af380-15ef-438e-ad51-04472348f1e6",
   "metadata": {},
   "source": [
    "### Step 1. Prepare Dataset + DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c4fa93-f636-4f5a-ac6b-92effa9dda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Twitter15Dataset(Dataset):\n",
    "    def __init__(self, graph_data_list):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with a list of graph data.\n",
    "\n",
    "        Args:\n",
    "            graph_data_list (list): List of graph dictionaries. \n",
    "                                    Each dictionary contains:\n",
    "                                    - 'x': node features tensor of shape (seq_len, feature_dim)\n",
    "                                    - 'edge_index': edge index tensor of shape (2, num_edges)\n",
    "                                    - 'y': label (int in range 0~3)\n",
    "        \"\"\"\n",
    "        self.graphs = graph_data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the total number of graphs\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the graph at index `idx`\n",
    "        graph = self.graphs[idx]\n",
    "        x = graph['x']  # Node features\n",
    "        edge_index = graph['edge_index']  # Edge indices\n",
    "        y = graph['y']  # Graph label\n",
    "\n",
    "        return x, edge_index, y\n",
    "\n",
    "def collate_fn(batch): \n",
    "    \"\"\"\n",
    "    Custom collate function to batch variable-length graph data.\n",
    "\n",
    "    Args:\n",
    "        batch (list of tuples): Each tuple is (x, edge_index, y)\n",
    "\n",
    "    Returns:\n",
    "        padded_xs (Tensor): Padded node features (batch_size, max_len, feature_dim)\n",
    "        masks (Tensor): Boolean masks indicating valid node positions (batch_size, max_len)\n",
    "        new_edge_indices (list): List of edge_index tensors (no batching done here)\n",
    "        ys (Tensor): Labels (batch_size,)\n",
    "    \"\"\"\n",
    "    xs, edge_indices, ys = zip(*batch)\n",
    "\n",
    "    max_len = max(x.shape[0] for x in xs)  # Maximum sequence length in batch\n",
    "    feature_dim = xs[0].shape[1]           # Dimensionality of node features\n",
    "\n",
    "    padded_xs = []\n",
    "    masks = []\n",
    "    new_edge_indices = []\n",
    "\n",
    "    for idx, (x, edge_index) in enumerate(zip(xs, edge_indices)):\n",
    "        seq_len = x.shape[0]\n",
    "        pad_len = max_len - seq_len\n",
    "\n",
    "        # Pad x to max_len if needed\n",
    "        if pad_len > 0:\n",
    "            pad = torch.zeros((pad_len, feature_dim), dtype=x.dtype)\n",
    "            x_padded = torch.cat([x, pad], dim=0)\n",
    "        else:\n",
    "            x_padded = x\n",
    "\n",
    "        padded_xs.append(x_padded)\n",
    "\n",
    "        # Create mask: 1 for valid tokens, 0 for padding\n",
    "        mask = torch.cat([torch.ones(seq_len), torch.zeros(pad_len)]).bool()\n",
    "        masks.append(mask)\n",
    "\n",
    "        # Edge indices are kept as is (no padding needed)\n",
    "        new_edge_indices.append(edge_index)\n",
    "\n",
    "    padded_xs = torch.stack(padded_xs)  # Stack padded features\n",
    "    masks = torch.stack(masks)          # Stack masks\n",
    "    ys = torch.tensor(ys)               # Convert labels to tensor\n",
    "\n",
    "    return padded_xs, masks, new_edge_indices, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2a3f99-0e53-4ce0-b328-e5a32368170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1043, Val: 223, Test: 224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load preprocessed graph data from file. Each item in the list is a graph (as a dictionary).\n",
    "# weights_only=False ensures full object is loaded (not just model weights).\n",
    "graph_data_list = torch.load(\"../processed/twitter15_graph_data_clean.pt\", weights_only=False)\n",
    "\n",
    "# Split the data into Train (70%) and Temp (30%) using a fixed random seed for reproducibility\n",
    "train_graphs, temp_graphs = train_test_split(graph_data_list, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split Temp into Validation (15%) and Test (15%) -> 0.5 * 30% = 15%\n",
    "val_graphs, test_graphs = train_test_split(temp_graphs, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the number of samples in each split\n",
    "print(f\"Train: {len(train_graphs)}, Val: {len(val_graphs)}, Test: {len(test_graphs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a066f7-510d-4732-bb5e-775da05f5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16  # Number of samples per batch during training and evaluation\n",
    "\n",
    "# Wrap the graph lists into PyTorch Dataset objects\n",
    "train_dataset = Twitter15Dataset(train_graphs)\n",
    "val_dataset = Twitter15Dataset(val_graphs)\n",
    "test_dataset = Twitter15Dataset(test_graphs)\n",
    "\n",
    "# Create DataLoaders to efficiently load data in batches\n",
    "# - shuffle=True for training to randomize sample order\n",
    "# - collate_fn=collate_fn handles padding and batching of variable-length graph inputs\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b6a26-4e2c-4b7e-9e8d-fe2966327260",
   "metadata": {},
   "source": [
    "### Step 2: MambaEncoder + Pooling + MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b613c42f-d68d-417c-ac2a-95ae85b3675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from mamba_ssm import Mamba                  # Sequence modeling block\n",
    "from torch_geometric.nn import GCNConv       # Graph Convolutional Network layer\n",
    "\n",
    "# Simple classification head: 2-layer MLP with ReLU activation\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, hidden_dim=256, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Mamba-based encoder for sequential (graph node) input\n",
    "class MambaEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=833, hidden_dim=128, num_layers=2, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)  # Project input to hidden dimension\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Mamba(d_model=hidden_dim),               # Mamba sequence layer\n",
    "                nn.Dropout(dropout_rate)                 # Dropout for regularization\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(hidden_dim)             # Normalize output\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, input_dim)\n",
    "            mask: (batch_size, seq_len) -> boolean tensor indicating valid positions\n",
    "        Returns:\n",
    "            x: (batch_size, seq_len, hidden_dim)\n",
    "        \"\"\"\n",
    "        x = self.input_proj(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# Pooling layer: averages node representations, ignoring padded positions\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, hidden_dim)\n",
    "            mask: (batch_size, seq_len)\n",
    "        Returns:\n",
    "            pooled: (batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        mask = mask.unsqueeze(-1)              # (batch_size, seq_len, 1)\n",
    "        x = x * mask                           # Zero out padded positions\n",
    "        sum_x = x.sum(dim=1)                   # Sum over valid positions\n",
    "        lengths = mask.sum(dim=1)              # Count of valid positions\n",
    "        pooled = sum_x / lengths.clamp(min=1e-6)  # Mean pooling\n",
    "        return pooled\n",
    "\n",
    "# Full classifier combining Mamba + GCN + Pooling + Classification head\n",
    "class MambaClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.input_norm = nn.LayerNorm(input_dim)  # Normalize input features\n",
    "        self.encoder = MambaEncoder(input_dim, hidden_dim, num_layers)\n",
    "\n",
    "        self.gnn_layer = GCNConv(hidden_dim, hidden_dim)  # GraphConv on encoded node features\n",
    "\n",
    "        self.pooling = MeanPooling()\n",
    "        self.classifier = ClassifierHead(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, mask, edge_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len, input_dim)\n",
    "            mask: (batch_size, seq_len)\n",
    "            edge_indices: list of (2, num_edges) tensors (graph structure for each sample)\n",
    "        Returns:\n",
    "            logits: (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        x = self.input_norm(x)                 # Normalize input\n",
    "\n",
    "        h = self.encoder(x, mask)              # Encode with Mamba layers -> (B, L, D)\n",
    "\n",
    "        # Apply GCN layer to each sample in the batch independently\n",
    "        h_gnn = []\n",
    "        for i in range(h.shape[0]):\n",
    "            hi = h[i]                          # (seq_len, hidden_dim)\n",
    "            ei = edge_indices[i].to(hi.device)  # Edge index for graph i\n",
    "\n",
    "            if ei.numel() == 0:                # If no edges, skip GCN\n",
    "                hi_gnn = hi\n",
    "            else:\n",
    "                hi_gnn = self.gnn_layer(hi, ei)\n",
    "\n",
    "            h_gnn.append(hi_gnn)\n",
    "\n",
    "        h = torch.stack(h_gnn, dim=0)          # (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        pooled = self.pooling(h, mask)         # Mean pool over valid nodes\n",
    "        logits = self.classifier(pooled)       # Predict class logits\n",
    "\n",
    "        logits = torch.clamp(logits, min=-10, max=10)  # Clamp for numerical stability\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690684a-800d-4030-b1eb-d77aef088022",
   "metadata": {},
   "source": [
    "### Step 3. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56735c89-d1ba-4314-8468-98f6df234351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Train the model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    all_preds = []   # Store predictions\n",
    "    all_labels = []  # Store true labels\n",
    "\n",
    "    for x, mask, edge_indices, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Move each tensor in edge_indices to the device\n",
    "        edge_indices = [ei.to(device) for ei in edge_indices]\n",
    "\n",
    "        # Replace NaNs in input with 0\n",
    "        x = torch.nan_to_num(x, nan=0.0)\n",
    "\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        logits = model(x, mask, edge_indices)  # Forward pass\n",
    "\n",
    "        # Debugging: Check for NaN or Inf in outputs\n",
    "        if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "            print(\"⚠️ Problematic batch detected!\")\n",
    "            print(f\"x shape: {x.shape}\")\n",
    "            print(f\"mask sum: {mask.sum(dim=1)}\")\n",
    "            print(f\"y: {y}\")\n",
    "            print(f\"logits max: {torch.nanmax(logits)}, min: {torch.nanmin(logits)}\")\n",
    "            continue\n",
    "\n",
    "        loss = loss_fn(logits, y)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()  # Update parameters\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)  # Accumulate batch loss\n",
    "\n",
    "        preds = logits.argmax(dim=-1)  # Get predicted class\n",
    "        all_preds.extend(preds.detach().cpu().tolist())  # Save predictions\n",
    "        all_labels.extend(y.cpu().tolist())  # Save true labels\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)  # Average loss\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)      # Accuracy\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')  # Macro F1-score\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "\n",
    "# Evaluate the model on validation data for one epoch\n",
    "def evaluate_one_epoch(model, val_loader, loss_fn, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for x, mask, edge_indices, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            y = y.to(device)\n",
    "            edge_indices = [ei.to(device) for ei in edge_indices]\n",
    "\n",
    "            logits = model(x, mask, edge_indices)\n",
    "            logits = torch.clamp(logits, min=-10, max=10)  # Clip output range\n",
    "\n",
    "            # Skip batch if output contains NaN or Inf\n",
    "            if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "                continue\n",
    "\n",
    "            loss = loss_fn(logits, y)\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "\n",
    "# Class to stop training early if performance does not improve\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last improvement\n",
    "            verbose (bool): Print message when early stopping\n",
    "            delta (float): Minimum change to qualify as improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_f1 = -float('inf')\n",
    "\n",
    "    # Call this function after each validation epoch\n",
    "    def __call__(self, val_f1, model):\n",
    "        score = val_f1  # Use F1-score as the metric\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_f1 = val_f1\n",
    "        elif score < self.best_score + self.delta:\n",
    "            # No improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True  # Trigger early stopping\n",
    "        else:\n",
    "            # Improvement observed\n",
    "            self.best_score = score\n",
    "            self.best_f1 = val_f1\n",
    "            self.counter = 0  # Reset counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a168a-6e41-461a-aa73-4a7014c0ec9c",
   "metadata": {},
   "source": [
    "### Step 4: Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ae78cff-6175-45b9-8539-2b5fb3d5ec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training with lr=5e-05, weight_decay=0.01\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3822 | Train Acc: 0.2800 | Train F1: 0.2684\n",
      "  Val   Loss: nan | Val   Acc: 0.2691 | Val   F1: 0.1898\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3449 | Train Acc: 0.3624 | Train F1: 0.2937\n",
      "  Val   Loss: nan | Val   Acc: 0.3587 | Val   F1: 0.3158\n",
      "Epoch 3:\n",
      "  Train Loss: 1.2716 | Train Acc: 0.4362 | Train F1: 0.3932\n",
      "  Val   Loss: nan | Val   Acc: 0.4215 | Val   F1: 0.4174\n",
      "Epoch 4:\n",
      "  Train Loss: 1.2061 | Train Acc: 0.4880 | Train F1: 0.4682\n",
      "  Val   Loss: nan | Val   Acc: 0.3543 | Val   F1: 0.3420\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 5:\n",
      "  Train Loss: 1.1519 | Train Acc: 0.5398 | Train F1: 0.5359\n",
      "  Val   Loss: nan | Val   Acc: 0.4439 | Val   F1: 0.4430\n",
      "Epoch 6:\n",
      "  Train Loss: 1.1034 | Train Acc: 0.5724 | Train F1: 0.5688\n",
      "  Val   Loss: nan | Val   Acc: 0.4529 | Val   F1: 0.4367\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 7:\n",
      "  Train Loss: 1.0547 | Train Acc: 0.5973 | Train F1: 0.5897\n",
      "  Val   Loss: nan | Val   Acc: 0.4709 | Val   F1: 0.4738\n",
      "Epoch 8:\n",
      "  Train Loss: 1.0079 | Train Acc: 0.6309 | Train F1: 0.6302\n",
      "  Val   Loss: nan | Val   Acc: 0.4709 | Val   F1: 0.4734\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 9:\n",
      "  Train Loss: 0.9648 | Train Acc: 0.6596 | Train F1: 0.6574\n",
      "  Val   Loss: nan | Val   Acc: 0.4664 | Val   F1: 0.4666\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 10:\n",
      "  Train Loss: 0.9165 | Train Acc: 0.7191 | Train F1: 0.7167\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4830\n",
      "Epoch 11:\n",
      "  Train Loss: 0.8842 | Train Acc: 0.7172 | Train F1: 0.7152\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4848\n",
      "Epoch 12:\n",
      "  Train Loss: 0.8445 | Train Acc: 0.7440 | Train F1: 0.7413\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.5000\n",
      "Epoch 13:\n",
      "  Train Loss: 0.8274 | Train Acc: 0.7565 | Train F1: 0.7560\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5278\n",
      "Epoch 14:\n",
      "  Train Loss: 0.7837 | Train Acc: 0.7814 | Train F1: 0.7797\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.5143\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 15:\n",
      "  Train Loss: 0.7530 | Train Acc: 0.8140 | Train F1: 0.8120\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5330\n",
      "Epoch 16:\n",
      "  Train Loss: 0.7343 | Train Acc: 0.8121 | Train F1: 0.8104\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5482\n",
      "Epoch 17:\n",
      "  Train Loss: 0.6975 | Train Acc: 0.8322 | Train F1: 0.8308\n",
      "  Val   Loss: nan | Val   Acc: 0.5247 | Val   F1: 0.5241\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 18:\n",
      "  Train Loss: 0.6758 | Train Acc: 0.8485 | Train F1: 0.8470\n",
      "  Val   Loss: nan | Val   Acc: 0.5202 | Val   F1: 0.5182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 19:\n",
      "  Train Loss: 0.6420 | Train Acc: 0.8591 | Train F1: 0.8581\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5764\n",
      "Epoch 20:\n",
      "  Train Loss: 0.6201 | Train Acc: 0.8907 | Train F1: 0.8899\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5680\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 21:\n",
      "  Train Loss: 0.6029 | Train Acc: 0.8849 | Train F1: 0.8842\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5714\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 22:\n",
      "  Train Loss: 0.5698 | Train Acc: 0.9099 | Train F1: 0.9093\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5902\n",
      "Epoch 23:\n",
      "  Train Loss: 0.5593 | Train Acc: 0.9147 | Train F1: 0.9142\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 24:\n",
      "  Train Loss: 0.5330 | Train Acc: 0.9233 | Train F1: 0.9229\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5879\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 25:\n",
      "  Train Loss: 0.5177 | Train Acc: 0.9281 | Train F1: 0.9275\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.6007\n",
      "Epoch 26:\n",
      "  Train Loss: 0.5046 | Train Acc: 0.9367 | Train F1: 0.9362\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4855 | Train Acc: 0.9492 | Train F1: 0.9488\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5845\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 28:\n",
      "  Train Loss: 0.4730 | Train Acc: 0.9482 | Train F1: 0.9478\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5653\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 29:\n",
      "  Train Loss: 0.4543 | Train Acc: 0.9597 | Train F1: 0.9594\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.5956\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 30:\n",
      "  Train Loss: 0.4408 | Train Acc: 0.9712 | Train F1: 0.9709\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5719\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 31:\n",
      "  Train Loss: 0.4352 | Train Acc: 0.9732 | Train F1: 0.9730\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6273\n",
      "Epoch 32:\n",
      "  Train Loss: 0.4229 | Train Acc: 0.9789 | Train F1: 0.9787\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6107\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 33:\n",
      "  Train Loss: 0.4258 | Train Acc: 0.9722 | Train F1: 0.9720\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 34:\n",
      "  Train Loss: 0.4056 | Train Acc: 0.9847 | Train F1: 0.9844\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6309\n",
      "Epoch 35:\n",
      "  Train Loss: 0.3928 | Train Acc: 0.9923 | Train F1: 0.9922\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6041\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 36:\n",
      "  Train Loss: 0.3901 | Train Acc: 0.9942 | Train F1: 0.9942\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5885\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 37:\n",
      "  Train Loss: 0.3815 | Train Acc: 0.9942 | Train F1: 0.9942\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6284\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 38:\n",
      "  Train Loss: 0.3825 | Train Acc: 0.9942 | Train F1: 0.9942\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6288\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 39:\n",
      "  Train Loss: 0.3783 | Train Acc: 0.9952 | Train F1: 0.9952\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6400\n",
      "Epoch 40:\n",
      "  Train Loss: 0.3751 | Train Acc: 0.9962 | Train F1: 0.9961\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6037\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 41:\n",
      "  Train Loss: 0.3697 | Train Acc: 0.9990 | Train F1: 0.9991\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6362\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 42:\n",
      "  Train Loss: 0.3645 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6020\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 43:\n",
      "  Train Loss: 0.3651 | Train Acc: 0.9990 | Train F1: 0.9991\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6234\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 44:\n",
      "  Train Loss: 0.3605 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6302\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 45:\n",
      "  Train Loss: 0.3583 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6361\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 46:\n",
      "  Train Loss: 0.3556 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6449\n",
      "Epoch 47:\n",
      "  Train Loss: 0.3553 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 48:\n",
      "  Train Loss: 0.3545 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6151\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 49:\n",
      "  Train Loss: 0.3530 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6413 | Val   F1: 0.6372\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 50:\n",
      "  Train Loss: 0.3521 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6413 | Val   F1: 0.6348\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 51:\n",
      "  Train Loss: 0.3519 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6413 | Val   F1: 0.6332\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 52:\n",
      "  Train Loss: 0.3521 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6459\n",
      "Epoch 53:\n",
      "  Train Loss: 0.3516 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6547 | Val   F1: 0.6487\n",
      "Epoch 54:\n",
      "  Train Loss: 0.3507 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6413 | Val   F1: 0.6368\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 55:\n",
      "  Train Loss: 0.3504 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6441\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 56:\n",
      "  Train Loss: 0.3505 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6422\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 57:\n",
      "  Train Loss: 0.3501 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6293\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 58:\n",
      "  Train Loss: 0.3499 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6212\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 59:\n",
      "  Train Loss: 0.3498 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6637 | Val   F1: 0.6587\n",
      "Epoch 60:\n",
      "  Train Loss: 0.3496 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6592 | Val   F1: 0.6523\n",
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      " Training with lr=5e-05, weight_decay=0.05\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3824 | Train Acc: 0.2819 | Train F1: 0.2109\n",
      "  Val   Loss: nan | Val   Acc: 0.3857 | Val   F1: 0.3461\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3465 | Train Acc: 0.4065 | Train F1: 0.3504\n",
      "  Val   Loss: nan | Val   Acc: 0.4215 | Val   F1: 0.3923\n",
      "Epoch 3:\n",
      "  Train Loss: 1.2370 | Train Acc: 0.4880 | Train F1: 0.4647\n",
      "  Val   Loss: nan | Val   Acc: 0.4753 | Val   F1: 0.4395\n",
      "Epoch 4:\n",
      "  Train Loss: 1.1387 | Train Acc: 0.5513 | Train F1: 0.5350\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4590\n",
      "Epoch 5:\n",
      "  Train Loss: 1.0756 | Train Acc: 0.5964 | Train F1: 0.5825\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5275\n",
      "Epoch 6:\n",
      "  Train Loss: 1.0246 | Train Acc: 0.6155 | Train F1: 0.6036\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5486\n",
      "Epoch 7:\n",
      "  Train Loss: 0.9774 | Train Acc: 0.6539 | Train F1: 0.6443\n",
      "  Val   Loss: nan | Val   Acc: 0.4664 | Val   F1: 0.4600\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 8:\n",
      "  Train Loss: 0.9367 | Train Acc: 0.6740 | Train F1: 0.6608\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 9:\n",
      "  Train Loss: 0.8951 | Train Acc: 0.7066 | Train F1: 0.6969\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4933\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 10:\n",
      "  Train Loss: 0.8698 | Train Acc: 0.7191 | Train F1: 0.7100\n",
      "  Val   Loss: nan | Val   Acc: 0.5022 | Val   F1: 0.4862\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 11:\n",
      "  Train Loss: 0.8328 | Train Acc: 0.7440 | Train F1: 0.7394\n",
      "  Val   Loss: nan | Val   Acc: 0.4933 | Val   F1: 0.4917\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 12:\n",
      "  Train Loss: 0.8005 | Train Acc: 0.7632 | Train F1: 0.7567\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5697\n",
      "Epoch 13:\n",
      "  Train Loss: 0.7749 | Train Acc: 0.7795 | Train F1: 0.7738\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5380\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 14:\n",
      "  Train Loss: 0.7508 | Train Acc: 0.7996 | Train F1: 0.7973\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6052\n",
      "Epoch 15:\n",
      "  Train Loss: 0.7300 | Train Acc: 0.8082 | Train F1: 0.8059\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5194\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 16:\n",
      "  Train Loss: 0.7119 | Train Acc: 0.8082 | Train F1: 0.8053\n",
      "  Val   Loss: nan | Val   Acc: 0.6413 | Val   F1: 0.6265\n",
      "Epoch 17:\n",
      "  Train Loss: 0.6727 | Train Acc: 0.8418 | Train F1: 0.8396\n",
      "  Val   Loss: nan | Val   Acc: 0.5561 | Val   F1: 0.5562\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 18:\n",
      "  Train Loss: 0.6464 | Train Acc: 0.8581 | Train F1: 0.8566\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5932\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 19:\n",
      "  Train Loss: 0.6426 | Train Acc: 0.8600 | Train F1: 0.8582\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5618\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 20:\n",
      "  Train Loss: 0.6275 | Train Acc: 0.8600 | Train F1: 0.8587\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5887\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 21:\n",
      "  Train Loss: 0.6100 | Train Acc: 0.8715 | Train F1: 0.8708\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6199\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 22:\n",
      "  Train Loss: 0.5718 | Train Acc: 0.8936 | Train F1: 0.8930\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6283\n",
      "Epoch 23:\n",
      "  Train Loss: 0.5567 | Train Acc: 0.9195 | Train F1: 0.9190\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6304\n",
      "Epoch 24:\n",
      "  Train Loss: 0.5346 | Train Acc: 0.9204 | Train F1: 0.9202\n",
      "  Val   Loss: nan | Val   Acc: 0.6682 | Val   F1: 0.6499\n",
      "Epoch 25:\n",
      "  Train Loss: 0.5306 | Train Acc: 0.9300 | Train F1: 0.9293\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6197\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 26:\n",
      "  Train Loss: 0.5167 | Train Acc: 0.9262 | Train F1: 0.9255\n",
      "  Val   Loss: nan | Val   Acc: 0.6682 | Val   F1: 0.6557\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4910 | Train Acc: 0.9463 | Train F1: 0.9460\n",
      "  Val   Loss: nan | Val   Acc: 0.6682 | Val   F1: 0.6577\n",
      "Epoch 28:\n",
      "  Train Loss: 0.4728 | Train Acc: 0.9616 | Train F1: 0.9613\n",
      "  Val   Loss: nan | Val   Acc: 0.6682 | Val   F1: 0.6608\n",
      "Epoch 29:\n",
      "  Train Loss: 0.4683 | Train Acc: 0.9540 | Train F1: 0.9538\n",
      "  Val   Loss: nan | Val   Acc: 0.6592 | Val   F1: 0.6520\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 30:\n",
      "  Train Loss: 0.4588 | Train Acc: 0.9607 | Train F1: 0.9603\n",
      "  Val   Loss: nan | Val   Acc: 0.6726 | Val   F1: 0.6626\n",
      "Epoch 31:\n",
      "  Train Loss: 0.4378 | Train Acc: 0.9722 | Train F1: 0.9720\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6342\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 32:\n",
      "  Train Loss: 0.4325 | Train Acc: 0.9770 | Train F1: 0.9768\n",
      "  Val   Loss: nan | Val   Acc: 0.6592 | Val   F1: 0.6569\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 33:\n",
      "  Train Loss: 0.4207 | Train Acc: 0.9751 | Train F1: 0.9750\n",
      "  Val   Loss: nan | Val   Acc: 0.6592 | Val   F1: 0.6558\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 34:\n",
      "  Train Loss: 0.4120 | Train Acc: 0.9837 | Train F1: 0.9836\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6444\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 35:\n",
      "  Train Loss: 0.4012 | Train Acc: 0.9875 | Train F1: 0.9875\n",
      "  Val   Loss: nan | Val   Acc: 0.6906 | Val   F1: 0.6811\n",
      "Epoch 36:\n",
      "  Train Loss: 0.3985 | Train Acc: 0.9885 | Train F1: 0.9884\n",
      "  Val   Loss: nan | Val   Acc: 0.6637 | Val   F1: 0.6542\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 37:\n",
      "  Train Loss: 0.3890 | Train Acc: 0.9933 | Train F1: 0.9933\n",
      "  Val   Loss: nan | Val   Acc: 0.6682 | Val   F1: 0.6656\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 38:\n",
      "  Train Loss: 0.3898 | Train Acc: 0.9923 | Train F1: 0.9923\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6330\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 39:\n",
      "  Train Loss: 0.3784 | Train Acc: 0.9942 | Train F1: 0.9942\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6404\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 40:\n",
      "  Train Loss: 0.3789 | Train Acc: 0.9933 | Train F1: 0.9933\n",
      "  Val   Loss: nan | Val   Acc: 0.6547 | Val   F1: 0.6502\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 41:\n",
      "  Train Loss: 0.3742 | Train Acc: 0.9971 | Train F1: 0.9971\n",
      "  Val   Loss: nan | Val   Acc: 0.6906 | Val   F1: 0.6840\n",
      "Epoch 42:\n",
      "  Train Loss: 0.3721 | Train Acc: 0.9962 | Train F1: 0.9961\n",
      "  Val   Loss: nan | Val   Acc: 0.6726 | Val   F1: 0.6691\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 43:\n",
      "  Train Loss: 0.3651 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: nan | Val   Acc: 0.6861 | Val   F1: 0.6818\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 44:\n",
      "  Train Loss: 0.3613 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6861 | Val   F1: 0.6825\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 45:\n",
      "  Train Loss: 0.3599 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6410\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 46:\n",
      "  Train Loss: 0.3578 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6592 | Val   F1: 0.6541\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 47:\n",
      "  Train Loss: 0.3578 | Train Acc: 0.9981 | Train F1: 0.9981\n",
      "  Val   Loss: nan | Val   Acc: 0.6816 | Val   F1: 0.6777\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 48:\n",
      "  Train Loss: 0.3562 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: nan | Val   Acc: 0.6637 | Val   F1: 0.6570\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 49:\n",
      "  Train Loss: 0.3559 | Train Acc: 0.9990 | Train F1: 0.9991\n",
      "  Val   Loss: nan | Val   Acc: 0.6637 | Val   F1: 0.6622\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 50:\n",
      "  Train Loss: 0.3540 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6637 | Val   F1: 0.6596\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 51:\n",
      "  Train Loss: 0.3547 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6682 | Val   F1: 0.6592\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping triggered!\n",
      "\n",
      " Training with lr=0.0001, weight_decay=0.01\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3809 | Train Acc: 0.2895 | Train F1: 0.2087\n",
      "  Val   Loss: nan | Val   Acc: 0.2601 | Val   F1: 0.2070\n",
      "Epoch 2:\n",
      "  Train Loss: 1.2833 | Train Acc: 0.4449 | Train F1: 0.4184\n",
      "  Val   Loss: nan | Val   Acc: 0.3632 | Val   F1: 0.3525\n",
      "Epoch 3:\n",
      "  Train Loss: 1.1546 | Train Acc: 0.5369 | Train F1: 0.5291\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4812\n",
      "Epoch 4:\n",
      "  Train Loss: 1.0613 | Train Acc: 0.5849 | Train F1: 0.5808\n",
      "  Val   Loss: nan | Val   Acc: 0.4619 | Val   F1: 0.4452\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 5:\n",
      "  Train Loss: 1.0083 | Train Acc: 0.6481 | Train F1: 0.6448\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4781\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 6:\n",
      "  Train Loss: 0.9422 | Train Acc: 0.6779 | Train F1: 0.6732\n",
      "  Val   Loss: nan | Val   Acc: 0.5247 | Val   F1: 0.4975\n",
      "Epoch 7:\n",
      "  Train Loss: 0.8704 | Train Acc: 0.7143 | Train F1: 0.7120\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5232\n",
      "Epoch 8:\n",
      "  Train Loss: 0.8238 | Train Acc: 0.7478 | Train F1: 0.7463\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5458\n",
      "Epoch 9:\n",
      "  Train Loss: 0.7855 | Train Acc: 0.7661 | Train F1: 0.7650\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5624\n",
      "Epoch 10:\n",
      "  Train Loss: 0.7350 | Train Acc: 0.8025 | Train F1: 0.8017\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.5155\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 11:\n",
      "  Train Loss: 0.6875 | Train Acc: 0.8245 | Train F1: 0.8239\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5867\n",
      "Epoch 12:\n",
      "  Train Loss: 0.6367 | Train Acc: 0.8591 | Train F1: 0.8583\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6138\n",
      "Epoch 13:\n",
      "  Train Loss: 0.6046 | Train Acc: 0.8802 | Train F1: 0.8799\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5716\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 14:\n",
      "  Train Loss: 0.5669 | Train Acc: 0.8965 | Train F1: 0.8963\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5799\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 15:\n",
      "  Train Loss: 0.5448 | Train Acc: 0.9118 | Train F1: 0.9117\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5599\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 16:\n",
      "  Train Loss: 0.5109 | Train Acc: 0.9310 | Train F1: 0.9305\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5941\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 17:\n",
      "  Train Loss: 0.4915 | Train Acc: 0.9377 | Train F1: 0.9375\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5985\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 18:\n",
      "  Train Loss: 0.4676 | Train Acc: 0.9444 | Train F1: 0.9443\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5874\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 19:\n",
      "  Train Loss: 0.4516 | Train Acc: 0.9578 | Train F1: 0.9576\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6006\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 20:\n",
      "  Train Loss: 0.4356 | Train Acc: 0.9616 | Train F1: 0.9615\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6042\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 21:\n",
      "  Train Loss: 0.4142 | Train Acc: 0.9741 | Train F1: 0.9742\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.5991\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 22:\n",
      "  Train Loss: 0.4026 | Train Acc: 0.9770 | Train F1: 0.9770\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5959\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping triggered!\n",
      "\n",
      " Training with lr=0.0001, weight_decay=0.05\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3829 | Train Acc: 0.2886 | Train F1: 0.2707\n",
      "  Val   Loss: nan | Val   Acc: 0.3094 | Val   F1: 0.2641\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3074 | Train Acc: 0.4017 | Train F1: 0.3576\n",
      "  Val   Loss: nan | Val   Acc: 0.4170 | Val   F1: 0.4134\n",
      "Epoch 3:\n",
      "  Train Loss: 1.1830 | Train Acc: 0.5187 | Train F1: 0.4949\n",
      "  Val   Loss: nan | Val   Acc: 0.4933 | Val   F1: 0.4892\n",
      "Epoch 4:\n",
      "  Train Loss: 1.0786 | Train Acc: 0.6088 | Train F1: 0.6009\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4588\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 5:\n",
      "  Train Loss: 0.9891 | Train Acc: 0.6491 | Train F1: 0.6394\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4584\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 6:\n",
      "  Train Loss: 0.9278 | Train Acc: 0.6750 | Train F1: 0.6680\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.5159\n",
      "Epoch 7:\n",
      "  Train Loss: 0.8476 | Train Acc: 0.7469 | Train F1: 0.7430\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5500\n",
      "Epoch 8:\n",
      "  Train Loss: 0.7983 | Train Acc: 0.7737 | Train F1: 0.7714\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5804\n",
      "Epoch 9:\n",
      "  Train Loss: 0.7477 | Train Acc: 0.7939 | Train F1: 0.7921\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5686\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 10:\n",
      "  Train Loss: 0.7130 | Train Acc: 0.8245 | Train F1: 0.8236\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.4857\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 11:\n",
      "  Train Loss: 0.6950 | Train Acc: 0.8207 | Train F1: 0.8191\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5626\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 12:\n",
      "  Train Loss: 0.6466 | Train Acc: 0.8562 | Train F1: 0.8547\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5221\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 13:\n",
      "  Train Loss: 0.6273 | Train Acc: 0.8629 | Train F1: 0.8623\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5836\n",
      "Epoch 14:\n",
      "  Train Loss: 0.5719 | Train Acc: 0.8993 | Train F1: 0.8986\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5689\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 15:\n",
      "  Train Loss: 0.5575 | Train Acc: 0.9041 | Train F1: 0.9037\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5679\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 16:\n",
      "  Train Loss: 0.5306 | Train Acc: 0.9195 | Train F1: 0.9192\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5700\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 17:\n",
      "  Train Loss: 0.4977 | Train Acc: 0.9310 | Train F1: 0.9304\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5922\n",
      "Epoch 18:\n",
      "  Train Loss: 0.4650 | Train Acc: 0.9626 | Train F1: 0.9628\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6095\n",
      "Epoch 19:\n",
      "  Train Loss: 0.4401 | Train Acc: 0.9712 | Train F1: 0.9710\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6056\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 20:\n",
      "  Train Loss: 0.4201 | Train Acc: 0.9770 | Train F1: 0.9768\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5684\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 21:\n",
      "  Train Loss: 0.4168 | Train Acc: 0.9760 | Train F1: 0.9758\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5938\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 22:\n",
      "  Train Loss: 0.4024 | Train Acc: 0.9875 | Train F1: 0.9874\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6109\n",
      "Epoch 23:\n",
      "  Train Loss: 0.3966 | Train Acc: 0.9818 | Train F1: 0.9819\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5939\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 24:\n",
      "  Train Loss: 0.3858 | Train Acc: 0.9895 | Train F1: 0.9894\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6099\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 25:\n",
      "  Train Loss: 0.3757 | Train Acc: 0.9923 | Train F1: 0.9924\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5519\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 26:\n",
      "  Train Loss: 0.3702 | Train Acc: 0.9923 | Train F1: 0.9924\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5960\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 27:\n",
      "  Train Loss: 0.3645 | Train Acc: 0.9933 | Train F1: 0.9933\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5489\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 28:\n",
      "  Train Loss: 0.3642 | Train Acc: 0.9962 | Train F1: 0.9961\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5804\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 29:\n",
      "  Train Loss: 0.3638 | Train Acc: 0.9952 | Train F1: 0.9952\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5637\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 30:\n",
      "  Train Loss: 0.3593 | Train Acc: 0.9962 | Train F1: 0.9962\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6130\n",
      "Epoch 31:\n",
      "  Train Loss: 0.3553 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5794\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 32:\n",
      "  Train Loss: 0.3535 | Train Acc: 0.9990 | Train F1: 0.9991\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6192\n",
      "Epoch 33:\n",
      "  Train Loss: 0.3537 | Train Acc: 0.9981 | Train F1: 0.9981\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6140\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 34:\n",
      "  Train Loss: 0.3521 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6198\n",
      "Epoch 35:\n",
      "  Train Loss: 0.3515 | Train Acc: 0.9990 | Train F1: 0.9991\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5938\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Epoch 36:\n",
      "  Train Loss: 0.3515 | Train Acc: 0.9990 | Train F1: 0.9991\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5896\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Epoch 37:\n",
      "  Train Loss: 0.3512 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6107\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Epoch 38:\n",
      "  Train Loss: 0.3499 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5976\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Epoch 39:\n",
      "  Train Loss: 0.3499 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6126\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Epoch 40:\n",
      "  Train Loss: 0.3498 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6109\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch 41:\n",
      "  Train Loss: 0.3495 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6119\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Epoch 42:\n",
      "  Train Loss: 0.3493 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6047\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Epoch 43:\n",
      "  Train Loss: 0.3492 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6138\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Epoch 44:\n",
      "  Train Loss: 0.3491 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6096\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping triggered!\n",
      "\n",
      " Grid Search completed!\n",
      "Best Hyperparameters: {'lr': 5e-05, 'weight_decay': 0.05}\n",
      "Best Val F1: 0.6840\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set all random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set random seed\n",
    "set_seed(42)\n",
    "\n",
    "# Create directory for saving model checkpoints\n",
    "os.makedirs(\"../checkpoints\", exist_ok=True)\n",
    "\n",
    "# Set device to GPU if available, otherwise CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define hyperparameter grid\n",
    "batch_size = 32\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_classes = 4\n",
    "\n",
    "learning_rates = [5e-5, 1e-4]\n",
    "weight_decays = [1e-2, 5e-2]\n",
    "patience = 10\n",
    "max_epochs = 60\n",
    "\n",
    "# Assume train_loader, val_loader, and test_loader are already defined\n",
    "\n",
    "# Define label smoothing cross entropy loss\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def smooth_cross_entropy(preds, targets, smoothing=0.1):\n",
    "    confidence = 1.0 - smoothing\n",
    "    logprobs = F.log_softmax(preds, dim=-1)\n",
    "    nll_loss = -logprobs.gather(dim=-1, index=targets.unsqueeze(1)).squeeze(1)\n",
    "    smooth_loss = -logprobs.mean(dim=-1)\n",
    "    loss = confidence * nll_loss + smoothing * smooth_loss\n",
    "    return loss.mean()\n",
    "\n",
    "loss_fn = smooth_cross_entropy\n",
    "\n",
    "# Store results of each hyperparameter configuration\n",
    "results = []\n",
    "\n",
    "# Track the best model\n",
    "best_val_f1 = -float('inf')\n",
    "best_model_state = None\n",
    "best_hparams = None\n",
    "\n",
    "# Grid search over learning rates and weight decays\n",
    "for lr in learning_rates:\n",
    "    for wd in weight_decays:\n",
    "        print(f\"\\n Training with lr={lr}, weight_decay={wd}\")\n",
    "\n",
    "        # Reinitialize the model and optimizer for each run\n",
    "        model = MambaClassifier(\n",
    "            input_dim=833,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            num_classes=num_classes\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        early_stopper = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(1, max_epochs + 1):\n",
    "            train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "            val_loss, val_acc, val_f1 = evaluate_one_epoch(model, val_loader, loss_fn, device)\n",
    "\n",
    "            print(f\"Epoch {epoch}:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}\")\n",
    "            print(f\"  Val   Loss: {val_loss:.4f} | Val   Acc: {val_acc:.4f} | Val   F1: {val_f1:.4f}\")\n",
    "\n",
    "            # Check early stopping condition\n",
    "            early_stopper(val_f1, model)\n",
    "\n",
    "            if early_stopper.early_stop:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "        # Log the result of this configuration\n",
    "        results.append({\n",
    "            \"learning_rate\": lr,\n",
    "            \"weight_decay\": wd,\n",
    "            \"val_f1\": early_stopper.best_f1\n",
    "        })\n",
    "\n",
    "        # Update the best model found so far\n",
    "        if early_stopper.best_f1 > best_val_f1:\n",
    "            best_val_f1 = early_stopper.best_f1\n",
    "            best_model_state = model.state_dict()\n",
    "            best_hparams = {\"lr\": lr, \"weight_decay\": wd}\n",
    "\n",
    "# Save the best model to disk\n",
    "save_path = \"../checkpoints/best_model_v2.pt\"\n",
    "torch.save(best_model_state, save_path)\n",
    "\n",
    "# Save all grid search results as a CSV file\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"../checkpoints/grid_search_results_v2.csv\", index=False)\n",
    "\n",
    "print(\"\\n Grid Search completed!\")\n",
    "print(f\"Best Hyperparameters: {best_hparams}\")\n",
    "print(f\"Best Val F1: {best_val_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f599e2-02ca-446c-918a-e4315c6c0956",
   "metadata": {},
   "source": [
    "### Step 5 Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23cde789-0caf-4879-81c7-c98768a06ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6027\n",
      "Test Macro-F1: 0.6029\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# 1. Load the best saved model checkpoint\n",
    "model.load_state_dict(torch.load(\"../checkpoints/best_model_v2.pt\"))\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# 2. Evaluate model performance on the test dataset\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for x, mask, edge_index, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        y = y.to(device)\n",
    "    \n",
    "        # Forward pass\n",
    "        logits = model(x, mask, edge_index)\n",
    "        preds = logits.argmax(dim=-1)  # Get predicted class\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "# 3. Compute evaluation metrics: accuracy and macro-averaged F1 score\n",
    "test_acc = accuracy_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Macro-F1: {test_f1:.4f}\")\n",
    "\n",
    "# 4. Generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot the confusion matrix with class labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=True,\n",
    "            xticklabels=[\"False\", \"Non-rumor\", \"True\", \"Unverified\"],\n",
    "            yticklabels=[\"False\", \"Non-rumor\", \"True\", \"Unverified\"])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix on Test Set\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "env_214"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
