{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851af380-15ef-438e-ad51-04472348f1e6",
   "metadata": {},
   "source": [
    "### Step 1. prepare Dataset + DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c4fa93-f636-4f5a-ac6b-92effa9dda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Define a custom Dataset for the Twitter15 graph-based data\n",
    "class Twitter15Dataset(Dataset):\n",
    "    def __init__(self, graph_data_list):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            graph_data_list (list): List of graph dictionaries.\n",
    "                                    Each graph is a dict with keys 'x', 'edge_index', and 'y'.\n",
    "        \"\"\"\n",
    "        self.graphs = graph_data_list  # Store the list of graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of graph samples\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the graph at index `idx`\n",
    "        graph = self.graphs[idx]\n",
    "        x = graph['x']  # Input features tensor of shape (seq_len, feature_dim)\n",
    "        y = graph['y']  # Label as an integer (e.g., 0~3)\n",
    "\n",
    "        return x, y  # Return features and label\n",
    "\n",
    "\n",
    "# Custom collate function for dynamic batching and padding\n",
    "def collate_fn(batch):\n",
    "    # Unpack the batch into features (xs) and labels (ys)\n",
    "    xs, ys = zip(*batch)\n",
    "\n",
    "    # Determine the maximum sequence length in this batch\n",
    "    max_len = max(x.shape[0] for x in xs)\n",
    "    feature_dim = xs[0].shape[1]  # Assume all sequences have the same feature dimension\n",
    "\n",
    "    padded_xs = []  # To store padded sequences\n",
    "    masks = []      # To store attention masks (1 for real token, 0 for padding)\n",
    "\n",
    "    for x in xs:\n",
    "        seq_len = x.shape[0]\n",
    "        pad_len = max_len - seq_len\n",
    "\n",
    "        # Pad the sequence with zeros if it's shorter than max_len\n",
    "        if pad_len > 0:\n",
    "            pad = torch.zeros((pad_len, feature_dim), dtype=x.dtype)\n",
    "            x_padded = torch.cat([x, pad], dim=0)  # Pad at the end\n",
    "        else:\n",
    "            x_padded = x  # No padding needed\n",
    "\n",
    "        # Create a mask: 1s for original tokens, 0s for padding\n",
    "        mask = torch.cat([torch.ones(seq_len), torch.zeros(pad_len)]).bool()\n",
    "\n",
    "        padded_xs.append(x_padded)\n",
    "        masks.append(mask)\n",
    "\n",
    "    # Stack all sequences and masks into batched tensors\n",
    "    padded_xs = torch.stack(padded_xs)    # Shape: (batch_size, max_len, feature_dim)\n",
    "    masks = torch.stack(masks)            # Shape: (batch_size, max_len)\n",
    "    ys = torch.tensor(ys)                 # Shape: (batch_size,)\n",
    "\n",
    "    return padded_xs, masks, ys  # Return padded inputs, masks, and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2a3f99-0e53-4ce0-b328-e5a32368170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1043, Val: 223, Test: 224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the preprocessed list of graphs (each graph is a dictionary)\n",
    "graph_data_list = torch.load(\"../processed/twitter15_graph_data_clean.pt\", weights_only=False)\n",
    "\n",
    "# Split the dataset into Train / Validation / Test sets with a 7:1:1 ratio\n",
    "# First split: 70% training, 30% temp (to be further split)\n",
    "train_graphs, temp_graphs = train_test_split(graph_data_list, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: 15% validation, 15% test from the 30% temp\n",
    "val_graphs, test_graphs = train_test_split(temp_graphs, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the number of samples in each split\n",
    "print(f\"Train: {len(train_graphs)}, Val: {len(val_graphs)}, Test: {len(test_graphs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1a066f7-510d-4732-bb5e-775da05f5cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders created successfully!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16  # Set the batch size for training and evaluation\n",
    "\n",
    "# Build datasets using the Twitter15Dataset class\n",
    "train_dataset = Twitter15Dataset(train_graphs)\n",
    "val_dataset = Twitter15Dataset(val_graphs)\n",
    "test_dataset = Twitter15Dataset(test_graphs)\n",
    "\n",
    "# Build DataLoaders for each dataset\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,               # Shuffle for training to improve generalization\n",
    "    collate_fn=collate_fn       # Custom function to pad sequences and create masks\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,              # No shuffle for validation\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,              # No shuffle for testing\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(\"DataLoaders created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b6a26-4e2c-4b7e-9e8d-fe2966327260",
   "metadata": {},
   "source": [
    "### Step 2: MambaEncoder + Pooling + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b613c42f-d68d-417c-ac2a-95ae85b3675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from mamba_ssm import Mamba  # Import the Mamba sequential state model\n",
    "\n",
    "# A simple classification head using two linear layers and ReLU activation\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, hidden_dim=256, num_classes=4):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # First linear layer\n",
    "            nn.ReLU(),                          # Non-linear activation\n",
    "            nn.Linear(hidden_dim, num_classes)  # Output layer for class logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)  # Returns logits (batch_size, num_classes)\n",
    "\n",
    "\n",
    "# Mamba-based encoder that applies multiple stacked Mamba layers\n",
    "class MambaEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=833, hidden_dim=128, num_layers=2, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)  # Project input to hidden dimension\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Mamba(d_model=hidden_dim),       # Mamba layer\n",
    "                nn.Dropout(dropout_rate)         # Regularization\n",
    "            ) for _ in range(num_layers)         # Repeat for specified number of layers\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(hidden_dim)     # Final layer normalization\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, input_dim)\n",
    "            mask: Bool tensor of shape (batch_size, seq_len) indicating valid (non-padded) tokens\n",
    "        \"\"\"\n",
    "        x = self.input_proj(x)  # Project input to hidden_dim\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)  # Apply Mamba + Dropout\n",
    "\n",
    "        x = self.norm(x)  # Normalize across hidden_dim\n",
    "        return x  # Shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "\n",
    "# Applies masked mean pooling across sequence length\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, hidden_dim)\n",
    "            mask: Bool tensor (batch_size, seq_len), where 1 means valid token\n",
    "        Returns:\n",
    "            pooled: Tensor of shape (batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        mask = mask.unsqueeze(-1)  # (batch_size, seq_len, 1) for broadcasting\n",
    "        x = x * mask  # Zero out padded positions\n",
    "\n",
    "        sum_x = x.sum(dim=1)             # Sum over sequence length\n",
    "        lengths = mask.sum(dim=1)        # Number of valid tokens per sample\n",
    "\n",
    "        pooled = sum_x / lengths.clamp(min=1e-6)  # Avoid divide-by-zero\n",
    "        return pooled  # Shape: (batch_size, hidden_dim)\n",
    "\n",
    "\n",
    "# Full classification model: normalization → encoder → pooling → classification\n",
    "class MambaClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(input_dim)                 # Normalize input features\n",
    "        self.encoder = MambaEncoder(input_dim, hidden_dim, num_layers)\n",
    "        self.pooling = MeanPooling()                        # Masked average pooling\n",
    "        self.classifier = ClassifierHead(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, input_dim)\n",
    "            mask: Bool tensor of shape (batch_size, seq_len)\n",
    "        Returns:\n",
    "            logits: Tensor of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        x = self.norm(x)               # Normalize input\n",
    "        h = self.encoder(x, mask)      # Apply Mamba encoder\n",
    "        pooled = self.pooling(h, mask) # Mean-pool over sequence\n",
    "        logits = self.classifier(pooled)  # Classify\n",
    "        logits = torch.clamp(logits, min=-10, max=10)  # Clip logits to avoid extreme values\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690684a-800d-4030-b1eb-d77aef088022",
   "metadata": {},
   "source": [
    "### Step 3. Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56735c89-d1ba-4314-8468-98f6df234351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for x, mask, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # make sure there is no nan in dataset\n",
    "        x = torch.nan_to_num(x, nan=0.0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x, mask)\n",
    "\n",
    "        # ===== 检查 logits 是否正常 =====\n",
    "        if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "            print(\"⚠️ Problematic batch detected!\")\n",
    "            print(f\"x shape: {x.shape}\")\n",
    "            print(f\"mask sum: {mask.sum(dim=1)}\")  # 每条链有效节点数量\n",
    "            print(f\"y: {y}\")\n",
    "            print(f\"logits max: {torch.nanmax(logits)}, min: {torch.nanmin(logits)}\")\n",
    "            continue  # 跳过这个batch\n",
    "        \n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        all_preds.extend(preds.detach().cpu().tolist())\n",
    "        all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "def evaluate_one_epoch(model, val_loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, mask, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x, mask)\n",
    "            logits = torch.clamp(logits, min=-10, max=10)\n",
    "\n",
    "            if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "                continue  # 验证时也保护\n",
    "            \n",
    "            loss = loss_fn(logits, y)\n",
    "            \n",
    "            running_loss += loss.item() * x.size(0)\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last improvement\n",
    "            verbose (bool): Print message when early stopping\n",
    "            delta (float): Minimum change to qualify as improvement\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_f1 = -float('inf')\n",
    "\n",
    "    def __call__(self, val_f1, model):\n",
    "        score = val_f1\n",
    "    \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_f1 = val_f1\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_f1 = val_f1\n",
    "            self.counter = 0\n",
    "    \n",
    "\n",
    "    # def __call__(self, val_f1, model, save_path):\n",
    "    #     score = val_f1\n",
    "\n",
    "    #     if self.best_score is None:\n",
    "    #         self.best_score = score\n",
    "    #         self.save_checkpoint(val_f1, model, save_path)\n",
    "    #     elif score < self.best_score + self.delta:\n",
    "    #         self.counter += 1\n",
    "    #         if self.verbose:\n",
    "    #             print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "    #         if self.counter >= self.patience:\n",
    "    #             self.early_stop = True\n",
    "    #     else:\n",
    "    #         self.best_score = score\n",
    "    #         self.save_checkpoint(val_f1, model, save_path)\n",
    "    #         self.counter = 0\n",
    "\n",
    "    # def save_checkpoint(self, val_f1, model, save_path):\n",
    "    #     \"\"\"Save model when val_f1 improves.\"\"\"\n",
    "    #     torch.save(model.state_dict(), save_path)\n",
    "    #     self.best_f1 = val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a168a-6e41-461a-aa73-4a7014c0ec9c",
   "metadata": {},
   "source": [
    "### Step 4: Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae78cff-6175-45b9-8539-2b5fb3d5ec35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Trying lr=0.0001, weight_decay=0.0 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3818 | Train Acc: 0.2953 | Train F1: 0.1998\n",
      "  Val   Loss: nan | Val   Acc: 0.2960 | Val   F1: 0.2252\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3063 | Train Acc: 0.4228 | Train F1: 0.4094\n",
      "  Val   Loss: nan | Val   Acc: 0.3946 | Val   F1: 0.3946\n",
      "Epoch 3:\n",
      "  Train Loss: 1.1614 | Train Acc: 0.5158 | Train F1: 0.5096\n",
      "  Val   Loss: nan | Val   Acc: 0.4753 | Val   F1: 0.4767\n",
      "Epoch 4:\n",
      "  Train Loss: 1.0618 | Train Acc: 0.6079 | Train F1: 0.6014\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.4969\n",
      "Epoch 5:\n",
      "  Train Loss: 0.9758 | Train Acc: 0.6673 | Train F1: 0.6620\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4588\n",
      "Epoch 6:\n",
      "  Train Loss: 0.9151 | Train Acc: 0.6961 | Train F1: 0.6899\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5672\n",
      "Epoch 7:\n",
      "  Train Loss: 0.8432 | Train Acc: 0.7536 | Train F1: 0.7503\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5307\n",
      "Epoch 8:\n",
      "  Train Loss: 0.7967 | Train Acc: 0.7632 | Train F1: 0.7604\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5547\n",
      "Epoch 9:\n",
      "  Train Loss: 0.7518 | Train Acc: 0.8082 | Train F1: 0.8074\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5819\n",
      "Epoch 10:\n",
      "  Train Loss: 0.7161 | Train Acc: 0.8159 | Train F1: 0.8141\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5727\n",
      "Epoch 11:\n",
      "  Train Loss: 0.6776 | Train Acc: 0.8437 | Train F1: 0.8433\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5733\n",
      "Epoch 12:\n",
      "  Train Loss: 0.6446 | Train Acc: 0.8523 | Train F1: 0.8513\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5731\n",
      "Epoch 13:\n",
      "  Train Loss: 0.6321 | Train Acc: 0.8696 | Train F1: 0.8695\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5782\n",
      "Epoch 14:\n",
      "  Train Loss: 0.5898 | Train Acc: 0.8907 | Train F1: 0.8910\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6019\n",
      "Epoch 15:\n",
      "  Train Loss: 0.5875 | Train Acc: 0.8945 | Train F1: 0.8938\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.5931\n",
      "Epoch 16:\n",
      "  Train Loss: 0.5500 | Train Acc: 0.9070 | Train F1: 0.9068\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5684\n",
      "Epoch 17:\n",
      "  Train Loss: 0.5328 | Train Acc: 0.9185 | Train F1: 0.9181\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5861\n",
      "Epoch 18:\n",
      "  Train Loss: 0.4975 | Train Acc: 0.9396 | Train F1: 0.9392\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5740\n",
      "Epoch 19:\n",
      "  Train Loss: 0.5056 | Train Acc: 0.9223 | Train F1: 0.9224\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6078\n",
      "Epoch 20:\n",
      "  Train Loss: 0.4724 | Train Acc: 0.9463 | Train F1: 0.9462\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5719\n",
      "Epoch 21:\n",
      "  Train Loss: 0.4480 | Train Acc: 0.9616 | Train F1: 0.9615\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5888\n",
      "Epoch 22:\n",
      "  Train Loss: 0.4317 | Train Acc: 0.9674 | Train F1: 0.9674\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6050\n",
      "Epoch 23:\n",
      "  Train Loss: 0.4189 | Train Acc: 0.9732 | Train F1: 0.9730\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5782\n",
      "Epoch 24:\n",
      "  Train Loss: 0.4101 | Train Acc: 0.9770 | Train F1: 0.9770\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6296\n",
      "Epoch 25:\n",
      "  Train Loss: 0.3925 | Train Acc: 0.9808 | Train F1: 0.9809\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6083\n",
      "Epoch 26:\n",
      "  Train Loss: 0.3931 | Train Acc: 0.9827 | Train F1: 0.9827\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6076\n",
      "Epoch 27:\n",
      "  Train Loss: 0.3869 | Train Acc: 0.9856 | Train F1: 0.9856\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6022\n",
      "Epoch 28:\n",
      "  Train Loss: 0.3802 | Train Acc: 0.9875 | Train F1: 0.9876\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6027\n",
      "Epoch 29:\n",
      "  Train Loss: 0.3734 | Train Acc: 0.9923 | Train F1: 0.9923\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5929\n",
      "Epoch 30:\n",
      "  Train Loss: 0.3649 | Train Acc: 0.9952 | Train F1: 0.9951\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6276\n",
      "Epoch 31:\n",
      "  Train Loss: 0.3615 | Train Acc: 0.9971 | Train F1: 0.9971\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5989\n",
      "Epoch 32:\n",
      "  Train Loss: 0.3643 | Train Acc: 0.9942 | Train F1: 0.9944\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5978\n",
      "Epoch 33:\n",
      "  Train Loss: 0.3573 | Train Acc: 0.9981 | Train F1: 0.9981\n",
      "  Val   Loss: nan | Val   Acc: 0.6547 | Val   F1: 0.6430\n",
      "Epoch 34:\n",
      "  Train Loss: 0.3545 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6109\n",
      "Epoch 35:\n",
      "  Train Loss: 0.3569 | Train Acc: 0.9971 | Train F1: 0.9972\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6126\n",
      "Epoch 36:\n",
      "  Train Loss: 0.3529 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6167\n",
      "Epoch 37:\n",
      "  Train Loss: 0.3543 | Train Acc: 0.9971 | Train F1: 0.9971\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6244\n",
      "Epoch 38:\n",
      "  Train Loss: 0.3512 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.6020\n",
      "Epoch 39:\n",
      "  Train Loss: 0.3512 | Train Acc: 0.9990 | Train F1: 0.9990\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6050\n",
      "Epoch 40:\n",
      "  Train Loss: 0.3499 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6150\n",
      "Epoch 41:\n",
      "  Train Loss: 0.3500 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6173\n",
      "Epoch 42:\n",
      "  Train Loss: 0.3495 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6268\n",
      "Epoch 43:\n",
      "  Train Loss: 0.3493 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6234\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=0.0001, weight_decay=0.01 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3810 | Train Acc: 0.2857 | Train F1: 0.2293\n",
      "  Val   Loss: nan | Val   Acc: 0.2601 | Val   F1: 0.1926\n",
      "Epoch 2:\n",
      "  Train Loss: 1.2983 | Train Acc: 0.4362 | Train F1: 0.3953\n",
      "  Val   Loss: nan | Val   Acc: 0.3946 | Val   F1: 0.3830\n",
      "Epoch 3:\n",
      "  Train Loss: 1.1656 | Train Acc: 0.5244 | Train F1: 0.5022\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4552\n",
      "Epoch 4:\n",
      "  Train Loss: 1.0662 | Train Acc: 0.6098 | Train F1: 0.5985\n",
      "  Val   Loss: nan | Val   Acc: 0.5112 | Val   F1: 0.5046\n",
      "Epoch 5:\n",
      "  Train Loss: 0.9762 | Train Acc: 0.6884 | Train F1: 0.6845\n",
      "  Val   Loss: nan | Val   Acc: 0.4753 | Val   F1: 0.4597\n",
      "Epoch 6:\n",
      "  Train Loss: 0.9266 | Train Acc: 0.6980 | Train F1: 0.6930\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4757\n",
      "Epoch 7:\n",
      "  Train Loss: 0.8665 | Train Acc: 0.7411 | Train F1: 0.7393\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5284\n",
      "Epoch 8:\n",
      "  Train Loss: 0.8385 | Train Acc: 0.7536 | Train F1: 0.7512\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5389\n",
      "Epoch 9:\n",
      "  Train Loss: 0.7933 | Train Acc: 0.7747 | Train F1: 0.7740\n",
      "  Val   Loss: nan | Val   Acc: 0.5561 | Val   F1: 0.5374\n",
      "Epoch 10:\n",
      "  Train Loss: 0.7292 | Train Acc: 0.8035 | Train F1: 0.8020\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5712\n",
      "Epoch 11:\n",
      "  Train Loss: 0.6944 | Train Acc: 0.8360 | Train F1: 0.8357\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5356\n",
      "Epoch 12:\n",
      "  Train Loss: 0.6762 | Train Acc: 0.8408 | Train F1: 0.8404\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.5935\n",
      "Epoch 13:\n",
      "  Train Loss: 0.6330 | Train Acc: 0.8696 | Train F1: 0.8697\n",
      "  Val   Loss: nan | Val   Acc: 0.5561 | Val   F1: 0.5545\n",
      "Epoch 14:\n",
      "  Train Loss: 0.6059 | Train Acc: 0.8802 | Train F1: 0.8803\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5957\n",
      "Epoch 15:\n",
      "  Train Loss: 0.5679 | Train Acc: 0.9051 | Train F1: 0.9052\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6058\n",
      "Epoch 16:\n",
      "  Train Loss: 0.5532 | Train Acc: 0.9156 | Train F1: 0.9157\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5589\n",
      "Epoch 17:\n",
      "  Train Loss: 0.5284 | Train Acc: 0.9185 | Train F1: 0.9188\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5971\n",
      "Epoch 18:\n",
      "  Train Loss: 0.5159 | Train Acc: 0.9195 | Train F1: 0.9196\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5803\n",
      "Epoch 19:\n",
      "  Train Loss: 0.4916 | Train Acc: 0.9319 | Train F1: 0.9323\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5619\n",
      "Epoch 20:\n",
      "  Train Loss: 0.4916 | Train Acc: 0.9338 | Train F1: 0.9339\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5642\n",
      "Epoch 21:\n",
      "  Train Loss: 0.4708 | Train Acc: 0.9444 | Train F1: 0.9447\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5959\n",
      "Epoch 22:\n",
      "  Train Loss: 0.4452 | Train Acc: 0.9597 | Train F1: 0.9599\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.5987\n",
      "Epoch 23:\n",
      "  Train Loss: 0.4480 | Train Acc: 0.9540 | Train F1: 0.9541\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6215\n",
      "Epoch 24:\n",
      "  Train Loss: 0.4280 | Train Acc: 0.9693 | Train F1: 0.9693\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5342\n",
      "Epoch 25:\n",
      "  Train Loss: 0.4294 | Train Acc: 0.9607 | Train F1: 0.9608\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6294\n",
      "Epoch 26:\n",
      "  Train Loss: 0.4023 | Train Acc: 0.9808 | Train F1: 0.9810\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6158\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4019 | Train Acc: 0.9770 | Train F1: 0.9769\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6151\n",
      "Epoch 28:\n",
      "  Train Loss: 0.3932 | Train Acc: 0.9856 | Train F1: 0.9856\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6276\n",
      "Epoch 29:\n",
      "  Train Loss: 0.3975 | Train Acc: 0.9789 | Train F1: 0.9787\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5754\n",
      "Epoch 30:\n",
      "  Train Loss: 0.3757 | Train Acc: 0.9933 | Train F1: 0.9933\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6175\n",
      "Epoch 31:\n",
      "  Train Loss: 0.3684 | Train Acc: 0.9962 | Train F1: 0.9962\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5785\n",
      "Epoch 32:\n",
      "  Train Loss: 0.3665 | Train Acc: 0.9962 | Train F1: 0.9962\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6159\n",
      "Epoch 33:\n",
      "  Train Loss: 0.3647 | Train Acc: 0.9942 | Train F1: 0.9942\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5947\n",
      "Epoch 34:\n",
      "  Train Loss: 0.3719 | Train Acc: 0.9904 | Train F1: 0.9904\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6104\n",
      "Epoch 35:\n",
      "  Train Loss: 0.3661 | Train Acc: 0.9942 | Train F1: 0.9942\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6044\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=0.0001, weight_decay=0.05 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3837 | Train Acc: 0.2905 | Train F1: 0.2623\n",
      "  Val   Loss: nan | Val   Acc: 0.2556 | Val   F1: 0.1799\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3086 | Train Acc: 0.3931 | Train F1: 0.3503\n",
      "  Val   Loss: nan | Val   Acc: 0.4395 | Val   F1: 0.4241\n",
      "Epoch 3:\n",
      "  Train Loss: 1.1836 | Train Acc: 0.4890 | Train F1: 0.4782\n",
      "  Val   Loss: nan | Val   Acc: 0.4395 | Val   F1: 0.4385\n",
      "Epoch 4:\n",
      "  Train Loss: 1.0918 | Train Acc: 0.5695 | Train F1: 0.5625\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4368\n",
      "Epoch 5:\n",
      "  Train Loss: 1.0447 | Train Acc: 0.6088 | Train F1: 0.6054\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4674\n",
      "Epoch 6:\n",
      "  Train Loss: 0.9610 | Train Acc: 0.6826 | Train F1: 0.6764\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5295\n",
      "Epoch 7:\n",
      "  Train Loss: 0.8999 | Train Acc: 0.7095 | Train F1: 0.7062\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5734\n",
      "Epoch 8:\n",
      "  Train Loss: 0.8459 | Train Acc: 0.7430 | Train F1: 0.7411\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5782\n",
      "Epoch 9:\n",
      "  Train Loss: 0.7882 | Train Acc: 0.7785 | Train F1: 0.7766\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5712\n",
      "Epoch 10:\n",
      "  Train Loss: 0.7561 | Train Acc: 0.8015 | Train F1: 0.8010\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5359\n",
      "Epoch 11:\n",
      "  Train Loss: 0.7336 | Train Acc: 0.8178 | Train F1: 0.8173\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5801\n",
      "Epoch 12:\n",
      "  Train Loss: 0.6820 | Train Acc: 0.8437 | Train F1: 0.8430\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5896\n",
      "Epoch 13:\n",
      "  Train Loss: 0.6471 | Train Acc: 0.8610 | Train F1: 0.8607\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5887\n",
      "Epoch 14:\n",
      "  Train Loss: 0.6177 | Train Acc: 0.8763 | Train F1: 0.8760\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6039\n",
      "Epoch 15:\n",
      "  Train Loss: 0.5947 | Train Acc: 0.8878 | Train F1: 0.8873\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6087\n",
      "Epoch 16:\n",
      "  Train Loss: 0.5736 | Train Acc: 0.9022 | Train F1: 0.9021\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6108\n",
      "Epoch 17:\n",
      "  Train Loss: 0.5543 | Train Acc: 0.9089 | Train F1: 0.9087\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6133\n",
      "Epoch 18:\n",
      "  Train Loss: 0.5321 | Train Acc: 0.9223 | Train F1: 0.9224\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6399\n",
      "Epoch 19:\n",
      "  Train Loss: 0.5180 | Train Acc: 0.9214 | Train F1: 0.9211\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6025\n",
      "Epoch 20:\n",
      "  Train Loss: 0.4854 | Train Acc: 0.9425 | Train F1: 0.9421\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6199\n",
      "Epoch 21:\n",
      "  Train Loss: 0.4773 | Train Acc: 0.9415 | Train F1: 0.9412\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6085\n",
      "Epoch 22:\n",
      "  Train Loss: 0.4629 | Train Acc: 0.9501 | Train F1: 0.9499\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5884\n",
      "Epoch 23:\n",
      "  Train Loss: 0.4566 | Train Acc: 0.9463 | Train F1: 0.9460\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6061\n",
      "Epoch 24:\n",
      "  Train Loss: 0.4389 | Train Acc: 0.9616 | Train F1: 0.9614\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5995\n",
      "Epoch 25:\n",
      "  Train Loss: 0.4258 | Train Acc: 0.9645 | Train F1: 0.9643\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5989\n",
      "Epoch 26:\n",
      "  Train Loss: 0.4196 | Train Acc: 0.9722 | Train F1: 0.9721\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6012\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4164 | Train Acc: 0.9732 | Train F1: 0.9731\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6022\n",
      "Epoch 28:\n",
      "  Train Loss: 0.3939 | Train Acc: 0.9837 | Train F1: 0.9836\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5608\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=5e-05, weight_decay=0.0 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3835 | Train Acc: 0.2771 | Train F1: 0.1463\n",
      "  Val   Loss: nan | Val   Acc: 0.2780 | Val   F1: 0.2239\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3596 | Train Acc: 0.3576 | Train F1: 0.3049\n",
      "  Val   Loss: nan | Val   Acc: 0.2511 | Val   F1: 0.1759\n",
      "Epoch 3:\n",
      "  Train Loss: 1.2812 | Train Acc: 0.4554 | Train F1: 0.4142\n",
      "  Val   Loss: nan | Val   Acc: 0.3453 | Val   F1: 0.3289\n",
      "Epoch 4:\n",
      "  Train Loss: 1.2097 | Train Acc: 0.5110 | Train F1: 0.4900\n",
      "  Val   Loss: nan | Val   Acc: 0.3722 | Val   F1: 0.3583\n",
      "Epoch 5:\n",
      "  Train Loss: 1.1453 | Train Acc: 0.5599 | Train F1: 0.5519\n",
      "  Val   Loss: nan | Val   Acc: 0.4709 | Val   F1: 0.4648\n",
      "Epoch 6:\n",
      "  Train Loss: 1.0760 | Train Acc: 0.6127 | Train F1: 0.6097\n",
      "  Val   Loss: nan | Val   Acc: 0.5022 | Val   F1: 0.4998\n",
      "Epoch 7:\n",
      "  Train Loss: 1.0130 | Train Acc: 0.6644 | Train F1: 0.6620\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5341\n",
      "Epoch 8:\n",
      "  Train Loss: 0.9471 | Train Acc: 0.6980 | Train F1: 0.6947\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5284\n",
      "Epoch 9:\n",
      "  Train Loss: 0.8904 | Train Acc: 0.7421 | Train F1: 0.7408\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5275\n",
      "Epoch 10:\n",
      "  Train Loss: 0.8411 | Train Acc: 0.7584 | Train F1: 0.7567\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5452\n",
      "Epoch 11:\n",
      "  Train Loss: 0.8154 | Train Acc: 0.7766 | Train F1: 0.7753\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5725\n",
      "Epoch 12:\n",
      "  Train Loss: 0.7789 | Train Acc: 0.7967 | Train F1: 0.7962\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5720\n",
      "Epoch 13:\n",
      "  Train Loss: 0.7446 | Train Acc: 0.8159 | Train F1: 0.8148\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5385\n",
      "Epoch 14:\n",
      "  Train Loss: 0.7146 | Train Acc: 0.8255 | Train F1: 0.8243\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6113\n",
      "Epoch 15:\n",
      "  Train Loss: 0.6908 | Train Acc: 0.8476 | Train F1: 0.8467\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5970\n",
      "Epoch 16:\n",
      "  Train Loss: 0.6711 | Train Acc: 0.8533 | Train F1: 0.8530\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6045\n",
      "Epoch 17:\n",
      "  Train Loss: 0.6377 | Train Acc: 0.8744 | Train F1: 0.8741\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6119\n",
      "Epoch 18:\n",
      "  Train Loss: 0.6111 | Train Acc: 0.8945 | Train F1: 0.8940\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6133\n",
      "Epoch 19:\n",
      "  Train Loss: 0.5995 | Train Acc: 0.8965 | Train F1: 0.8963\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5640\n",
      "Epoch 20:\n",
      "  Train Loss: 0.5842 | Train Acc: 0.8907 | Train F1: 0.8907\n",
      "  Val   Loss: nan | Val   Acc: 0.6682 | Val   F1: 0.6521\n",
      "Epoch 21:\n",
      "  Train Loss: 0.5490 | Train Acc: 0.9214 | Train F1: 0.9210\n",
      "  Val   Loss: nan | Val   Acc: 0.6547 | Val   F1: 0.6430\n",
      "Epoch 22:\n",
      "  Train Loss: 0.5465 | Train Acc: 0.9175 | Train F1: 0.9172\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6125\n",
      "Epoch 23:\n",
      "  Train Loss: 0.5235 | Train Acc: 0.9300 | Train F1: 0.9298\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5979\n",
      "Epoch 24:\n",
      "  Train Loss: 0.5009 | Train Acc: 0.9444 | Train F1: 0.9444\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6258\n",
      "Epoch 25:\n",
      "  Train Loss: 0.5076 | Train Acc: 0.9377 | Train F1: 0.9375\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6177\n",
      "Epoch 26:\n",
      "  Train Loss: 0.4840 | Train Acc: 0.9463 | Train F1: 0.9464\n",
      "  Val   Loss: nan | Val   Acc: 0.6547 | Val   F1: 0.6512\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4613 | Train Acc: 0.9597 | Train F1: 0.9596\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6466\n",
      "Epoch 28:\n",
      "  Train Loss: 0.4469 | Train Acc: 0.9597 | Train F1: 0.9595\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6222\n",
      "Epoch 29:\n",
      "  Train Loss: 0.4486 | Train Acc: 0.9588 | Train F1: 0.9585\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6051\n",
      "Epoch 30:\n",
      "  Train Loss: 0.4266 | Train Acc: 0.9722 | Train F1: 0.9723\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5876\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=5e-05, weight_decay=0.01 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3839 | Train Acc: 0.2905 | Train F1: 0.2340\n",
      "  Val   Loss: nan | Val   Acc: 0.2556 | Val   F1: 0.1701\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3698 | Train Acc: 0.3327 | Train F1: 0.2747\n",
      "  Val   Loss: nan | Val   Acc: 0.3229 | Val   F1: 0.2877\n",
      "Epoch 3:\n",
      "  Train Loss: 1.3063 | Train Acc: 0.4372 | Train F1: 0.3895\n",
      "  Val   Loss: nan | Val   Acc: 0.4260 | Val   F1: 0.3886\n",
      "Epoch 4:\n",
      "  Train Loss: 1.2045 | Train Acc: 0.5206 | Train F1: 0.5025\n",
      "  Val   Loss: nan | Val   Acc: 0.4081 | Val   F1: 0.3877\n",
      "Epoch 5:\n",
      "  Train Loss: 1.1201 | Train Acc: 0.5753 | Train F1: 0.5655\n",
      "  Val   Loss: nan | Val   Acc: 0.3767 | Val   F1: 0.3638\n",
      "Epoch 6:\n",
      "  Train Loss: 1.0517 | Train Acc: 0.6357 | Train F1: 0.6297\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.4971\n",
      "Epoch 7:\n",
      "  Train Loss: 0.9857 | Train Acc: 0.6711 | Train F1: 0.6668\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5190\n",
      "Epoch 8:\n",
      "  Train Loss: 0.9341 | Train Acc: 0.7057 | Train F1: 0.7032\n",
      "  Val   Loss: nan | Val   Acc: 0.4888 | Val   F1: 0.4848\n",
      "Epoch 9:\n",
      "  Train Loss: 0.8824 | Train Acc: 0.7421 | Train F1: 0.7387\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.5056\n",
      "Epoch 10:\n",
      "  Train Loss: 0.8371 | Train Acc: 0.7622 | Train F1: 0.7604\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5436\n",
      "Epoch 11:\n",
      "  Train Loss: 0.8043 | Train Acc: 0.7881 | Train F1: 0.7863\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5401\n",
      "Epoch 12:\n",
      "  Train Loss: 0.7707 | Train Acc: 0.8015 | Train F1: 0.8000\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5326\n",
      "Epoch 13:\n",
      "  Train Loss: 0.7383 | Train Acc: 0.8284 | Train F1: 0.8272\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5575\n",
      "Epoch 14:\n",
      "  Train Loss: 0.7177 | Train Acc: 0.8284 | Train F1: 0.8276\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5858\n",
      "Epoch 15:\n",
      "  Train Loss: 0.6860 | Train Acc: 0.8533 | Train F1: 0.8527\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5750\n",
      "Epoch 16:\n",
      "  Train Loss: 0.6665 | Train Acc: 0.8610 | Train F1: 0.8603\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5500\n",
      "Epoch 17:\n",
      "  Train Loss: 0.6347 | Train Acc: 0.8754 | Train F1: 0.8751\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5757\n",
      "Epoch 18:\n",
      "  Train Loss: 0.6256 | Train Acc: 0.8773 | Train F1: 0.8774\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5865\n",
      "Epoch 19:\n",
      "  Train Loss: 0.5952 | Train Acc: 0.8955 | Train F1: 0.8955\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5395\n",
      "Epoch 20:\n",
      "  Train Loss: 0.5746 | Train Acc: 0.9070 | Train F1: 0.9071\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5889\n",
      "Epoch 21:\n",
      "  Train Loss: 0.5473 | Train Acc: 0.9156 | Train F1: 0.9156\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5657\n",
      "Epoch 22:\n",
      "  Train Loss: 0.5312 | Train Acc: 0.9310 | Train F1: 0.9308\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6022\n",
      "Epoch 23:\n",
      "  Train Loss: 0.5155 | Train Acc: 0.9329 | Train F1: 0.9329\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5668\n",
      "Epoch 24:\n",
      "  Train Loss: 0.5107 | Train Acc: 0.9367 | Train F1: 0.9367\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6075\n",
      "Epoch 25:\n",
      "  Train Loss: 0.4773 | Train Acc: 0.9530 | Train F1: 0.9529\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6371\n",
      "Epoch 26:\n",
      "  Train Loss: 0.4834 | Train Acc: 0.9492 | Train F1: 0.9489\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6212\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4587 | Train Acc: 0.9616 | Train F1: 0.9616\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6040\n",
      "Epoch 28:\n",
      "  Train Loss: 0.4397 | Train Acc: 0.9712 | Train F1: 0.9711\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5988\n",
      "Epoch 29:\n",
      "  Train Loss: 0.4299 | Train Acc: 0.9732 | Train F1: 0.9730\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6117\n",
      "Epoch 30:\n",
      "  Train Loss: 0.4244 | Train Acc: 0.9770 | Train F1: 0.9768\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5953\n",
      "Epoch 31:\n",
      "  Train Loss: 0.4070 | Train Acc: 0.9856 | Train F1: 0.9856\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5994\n",
      "Epoch 32:\n",
      "  Train Loss: 0.4099 | Train Acc: 0.9808 | Train F1: 0.9807\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6130\n",
      "Epoch 33:\n",
      "  Train Loss: 0.4037 | Train Acc: 0.9866 | Train F1: 0.9865\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5849\n",
      "Epoch 34:\n",
      "  Train Loss: 0.3902 | Train Acc: 0.9904 | Train F1: 0.9903\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5946\n",
      "Epoch 35:\n",
      "  Train Loss: 0.3875 | Train Acc: 0.9895 | Train F1: 0.9893\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6154\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=5e-05, weight_decay=0.05 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3840 | Train Acc: 0.2752 | Train F1: 0.2304\n",
      "  Val   Loss: nan | Val   Acc: 0.2825 | Val   F1: 0.2248\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3607 | Train Acc: 0.3663 | Train F1: 0.2897\n",
      "  Val   Loss: nan | Val   Acc: 0.2601 | Val   F1: 0.2339\n",
      "Epoch 3:\n",
      "  Train Loss: 1.2769 | Train Acc: 0.4353 | Train F1: 0.3814\n",
      "  Val   Loss: nan | Val   Acc: 0.3453 | Val   F1: 0.3114\n",
      "Epoch 4:\n",
      "  Train Loss: 1.1959 | Train Acc: 0.4947 | Train F1: 0.4721\n",
      "  Val   Loss: nan | Val   Acc: 0.4081 | Val   F1: 0.3955\n",
      "Epoch 5:\n",
      "  Train Loss: 1.1224 | Train Acc: 0.5436 | Train F1: 0.5270\n",
      "  Val   Loss: nan | Val   Acc: 0.4260 | Val   F1: 0.4134\n",
      "Epoch 6:\n",
      "  Train Loss: 1.0553 | Train Acc: 0.6040 | Train F1: 0.5849\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4743\n",
      "Epoch 7:\n",
      "  Train Loss: 1.0162 | Train Acc: 0.6366 | Train F1: 0.6222\n",
      "  Val   Loss: nan | Val   Acc: 0.4529 | Val   F1: 0.4481\n",
      "Epoch 8:\n",
      "  Train Loss: 0.9803 | Train Acc: 0.6654 | Train F1: 0.6566\n",
      "  Val   Loss: nan | Val   Acc: 0.5112 | Val   F1: 0.5093\n",
      "Epoch 9:\n",
      "  Train Loss: 0.9164 | Train Acc: 0.7018 | Train F1: 0.6926\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5474\n",
      "Epoch 10:\n",
      "  Train Loss: 0.8835 | Train Acc: 0.7258 | Train F1: 0.7196\n",
      "  Val   Loss: nan | Val   Acc: 0.5561 | Val   F1: 0.5493\n",
      "Epoch 11:\n",
      "  Train Loss: 0.8360 | Train Acc: 0.7593 | Train F1: 0.7538\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5577\n",
      "Epoch 12:\n",
      "  Train Loss: 0.7990 | Train Acc: 0.7747 | Train F1: 0.7699\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5447\n",
      "Epoch 13:\n",
      "  Train Loss: 0.7714 | Train Acc: 0.7977 | Train F1: 0.7953\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5399\n",
      "Epoch 14:\n",
      "  Train Loss: 0.7461 | Train Acc: 0.8082 | Train F1: 0.8050\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5605\n",
      "Epoch 15:\n",
      "  Train Loss: 0.7207 | Train Acc: 0.8245 | Train F1: 0.8224\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5725\n",
      "Epoch 16:\n",
      "  Train Loss: 0.6907 | Train Acc: 0.8495 | Train F1: 0.8487\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5818\n",
      "Epoch 17:\n",
      "  Train Loss: 0.6766 | Train Acc: 0.8533 | Train F1: 0.8520\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5631\n",
      "Epoch 18:\n",
      "  Train Loss: 0.6481 | Train Acc: 0.8610 | Train F1: 0.8597\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5737\n",
      "Epoch 19:\n",
      "  Train Loss: 0.6176 | Train Acc: 0.8821 | Train F1: 0.8814\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5903\n",
      "Epoch 20:\n",
      "  Train Loss: 0.5990 | Train Acc: 0.8965 | Train F1: 0.8960\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5578\n",
      "Epoch 21:\n",
      "  Train Loss: 0.5848 | Train Acc: 0.8878 | Train F1: 0.8872\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5731\n",
      "Epoch 22:\n",
      "  Train Loss: 0.5696 | Train Acc: 0.9012 | Train F1: 0.9011\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6245\n",
      "Epoch 23:\n",
      "  Train Loss: 0.5588 | Train Acc: 0.9128 | Train F1: 0.9126\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5677\n",
      "Epoch 24:\n",
      "  Train Loss: 0.5240 | Train Acc: 0.9281 | Train F1: 0.9281\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5820\n",
      "Epoch 25:\n",
      "  Train Loss: 0.5155 | Train Acc: 0.9281 | Train F1: 0.9278\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5799\n",
      "Epoch 26:\n",
      "  Train Loss: 0.4968 | Train Acc: 0.9425 | Train F1: 0.9423\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6144\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4937 | Train Acc: 0.9444 | Train F1: 0.9442\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6061\n",
      "Epoch 28:\n",
      "  Train Loss: 0.4723 | Train Acc: 0.9530 | Train F1: 0.9530\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5970\n",
      "Epoch 29:\n",
      "  Train Loss: 0.4587 | Train Acc: 0.9597 | Train F1: 0.9599\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.5958\n",
      "Epoch 30:\n",
      "  Train Loss: 0.4432 | Train Acc: 0.9655 | Train F1: 0.9654\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5981\n",
      "Epoch 31:\n",
      "  Train Loss: 0.4444 | Train Acc: 0.9636 | Train F1: 0.9637\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6021\n",
      "Epoch 32:\n",
      "  Train Loss: 0.4233 | Train Acc: 0.9760 | Train F1: 0.9761\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5954\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=1e-05, weight_decay=0.0 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3863 | Train Acc: 0.2522 | Train F1: 0.1252\n",
      "  Val   Loss: nan | Val   Acc: 0.2870 | Val   F1: 0.1544\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3838 | Train Acc: 0.2752 | Train F1: 0.1765\n",
      "  Val   Loss: nan | Val   Acc: 0.3094 | Val   F1: 0.2298\n",
      "Epoch 3:\n",
      "  Train Loss: 1.3813 | Train Acc: 0.3193 | Train F1: 0.2519\n",
      "  Val   Loss: nan | Val   Acc: 0.3408 | Val   F1: 0.2804\n",
      "Epoch 4:\n",
      "  Train Loss: 1.3778 | Train Acc: 0.3480 | Train F1: 0.2827\n",
      "  Val   Loss: nan | Val   Acc: 0.3318 | Val   F1: 0.2930\n",
      "Epoch 5:\n",
      "  Train Loss: 1.3730 | Train Acc: 0.3864 | Train F1: 0.3266\n",
      "  Val   Loss: nan | Val   Acc: 0.3408 | Val   F1: 0.2977\n",
      "Epoch 6:\n",
      "  Train Loss: 1.3655 | Train Acc: 0.4036 | Train F1: 0.3458\n",
      "  Val   Loss: nan | Val   Acc: 0.3274 | Val   F1: 0.2907\n",
      "Epoch 7:\n",
      "  Train Loss: 1.3531 | Train Acc: 0.4161 | Train F1: 0.3527\n",
      "  Val   Loss: nan | Val   Acc: 0.3587 | Val   F1: 0.3241\n",
      "Epoch 8:\n",
      "  Train Loss: 1.3334 | Train Acc: 0.4382 | Train F1: 0.3797\n",
      "  Val   Loss: nan | Val   Acc: 0.3498 | Val   F1: 0.3128\n",
      "Epoch 9:\n",
      "  Train Loss: 1.3078 | Train Acc: 0.4621 | Train F1: 0.4151\n",
      "  Val   Loss: nan | Val   Acc: 0.3632 | Val   F1: 0.3399\n",
      "Epoch 10:\n",
      "  Train Loss: 1.2810 | Train Acc: 0.4736 | Train F1: 0.4219\n",
      "  Val   Loss: nan | Val   Acc: 0.3812 | Val   F1: 0.3526\n",
      "Epoch 11:\n",
      "  Train Loss: 1.2557 | Train Acc: 0.4823 | Train F1: 0.4417\n",
      "  Val   Loss: nan | Val   Acc: 0.3946 | Val   F1: 0.3780\n",
      "Epoch 12:\n",
      "  Train Loss: 1.2331 | Train Acc: 0.4966 | Train F1: 0.4578\n",
      "  Val   Loss: nan | Val   Acc: 0.4126 | Val   F1: 0.3978\n",
      "Epoch 13:\n",
      "  Train Loss: 1.2136 | Train Acc: 0.5110 | Train F1: 0.4808\n",
      "  Val   Loss: nan | Val   Acc: 0.3946 | Val   F1: 0.3831\n",
      "Epoch 14:\n",
      "  Train Loss: 1.1947 | Train Acc: 0.5168 | Train F1: 0.4879\n",
      "  Val   Loss: nan | Val   Acc: 0.4170 | Val   F1: 0.4028\n",
      "Epoch 15:\n",
      "  Train Loss: 1.1831 | Train Acc: 0.5244 | Train F1: 0.4933\n",
      "  Val   Loss: nan | Val   Acc: 0.4260 | Val   F1: 0.4171\n",
      "Epoch 16:\n",
      "  Train Loss: 1.1620 | Train Acc: 0.5417 | Train F1: 0.5158\n",
      "  Val   Loss: nan | Val   Acc: 0.4170 | Val   F1: 0.4068\n",
      "Epoch 17:\n",
      "  Train Loss: 1.1472 | Train Acc: 0.5580 | Train F1: 0.5366\n",
      "  Val   Loss: nan | Val   Acc: 0.4305 | Val   F1: 0.4238\n",
      "Epoch 18:\n",
      "  Train Loss: 1.1304 | Train Acc: 0.5686 | Train F1: 0.5517\n",
      "  Val   Loss: nan | Val   Acc: 0.4305 | Val   F1: 0.4189\n",
      "Epoch 19:\n",
      "  Train Loss: 1.1165 | Train Acc: 0.5762 | Train F1: 0.5569\n",
      "  Val   Loss: nan | Val   Acc: 0.4529 | Val   F1: 0.4465\n",
      "Epoch 20:\n",
      "  Train Loss: 1.1019 | Train Acc: 0.5887 | Train F1: 0.5754\n",
      "  Val   Loss: nan | Val   Acc: 0.4350 | Val   F1: 0.4263\n",
      "Epoch 21:\n",
      "  Train Loss: 1.0868 | Train Acc: 0.5896 | Train F1: 0.5750\n",
      "  Val   Loss: nan | Val   Acc: 0.4529 | Val   F1: 0.4484\n",
      "Epoch 22:\n",
      "  Train Loss: 1.0712 | Train Acc: 0.6050 | Train F1: 0.5855\n",
      "  Val   Loss: nan | Val   Acc: 0.4439 | Val   F1: 0.4361\n",
      "Epoch 23:\n",
      "  Train Loss: 1.0636 | Train Acc: 0.6107 | Train F1: 0.5998\n",
      "  Val   Loss: nan | Val   Acc: 0.4574 | Val   F1: 0.4504\n",
      "Epoch 24:\n",
      "  Train Loss: 1.0478 | Train Acc: 0.6194 | Train F1: 0.6074\n",
      "  Val   Loss: nan | Val   Acc: 0.4529 | Val   F1: 0.4498\n",
      "Epoch 25:\n",
      "  Train Loss: 1.0384 | Train Acc: 0.6318 | Train F1: 0.6232\n",
      "  Val   Loss: nan | Val   Acc: 0.4619 | Val   F1: 0.4556\n",
      "Epoch 26:\n",
      "  Train Loss: 1.0218 | Train Acc: 0.6290 | Train F1: 0.6140\n",
      "  Val   Loss: nan | Val   Acc: 0.4529 | Val   F1: 0.4489\n",
      "Epoch 27:\n",
      "  Train Loss: 1.0088 | Train Acc: 0.6395 | Train F1: 0.6270\n",
      "  Val   Loss: nan | Val   Acc: 0.4619 | Val   F1: 0.4586\n",
      "Epoch 28:\n",
      "  Train Loss: 0.9972 | Train Acc: 0.6520 | Train F1: 0.6415\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4773\n",
      "Epoch 29:\n",
      "  Train Loss: 0.9844 | Train Acc: 0.6577 | Train F1: 0.6478\n",
      "  Val   Loss: nan | Val   Acc: 0.4753 | Val   F1: 0.4700\n",
      "Epoch 30:\n",
      "  Train Loss: 0.9754 | Train Acc: 0.6635 | Train F1: 0.6516\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4813\n",
      "Epoch 31:\n",
      "  Train Loss: 0.9659 | Train Acc: 0.6798 | Train F1: 0.6729\n",
      "  Val   Loss: nan | Val   Acc: 0.4753 | Val   F1: 0.4730\n",
      "Epoch 32:\n",
      "  Train Loss: 0.9533 | Train Acc: 0.6798 | Train F1: 0.6719\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.4958\n",
      "Epoch 33:\n",
      "  Train Loss: 0.9438 | Train Acc: 0.6855 | Train F1: 0.6767\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.4951\n",
      "Epoch 34:\n",
      "  Train Loss: 0.9355 | Train Acc: 0.7018 | Train F1: 0.6944\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4951\n",
      "Epoch 35:\n",
      "  Train Loss: 0.9238 | Train Acc: 0.7057 | Train F1: 0.6992\n",
      "  Val   Loss: nan | Val   Acc: 0.4933 | Val   F1: 0.4895\n",
      "Epoch 36:\n",
      "  Train Loss: 0.9125 | Train Acc: 0.7124 | Train F1: 0.7055\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4917\n",
      "Epoch 37:\n",
      "  Train Loss: 0.9043 | Train Acc: 0.7133 | Train F1: 0.7054\n",
      "  Val   Loss: nan | Val   Acc: 0.4753 | Val   F1: 0.4734\n",
      "Epoch 38:\n",
      "  Train Loss: 0.9003 | Train Acc: 0.7133 | Train F1: 0.7069\n",
      "  Val   Loss: nan | Val   Acc: 0.5112 | Val   F1: 0.5040\n",
      "Epoch 39:\n",
      "  Train Loss: 0.8860 | Train Acc: 0.7325 | Train F1: 0.7267\n",
      "  Val   Loss: nan | Val   Acc: 0.5022 | Val   F1: 0.4981\n",
      "Epoch 40:\n",
      "  Train Loss: 0.8765 | Train Acc: 0.7421 | Train F1: 0.7370\n",
      "  Val   Loss: nan | Val   Acc: 0.4888 | Val   F1: 0.4823\n",
      "Epoch 41:\n",
      "  Train Loss: 0.8676 | Train Acc: 0.7315 | Train F1: 0.7235\n",
      "  Val   Loss: nan | Val   Acc: 0.4888 | Val   F1: 0.4859\n",
      "Epoch 42:\n",
      "  Train Loss: 0.8587 | Train Acc: 0.7507 | Train F1: 0.7471\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4897\n",
      "Epoch 43:\n",
      "  Train Loss: 0.8508 | Train Acc: 0.7498 | Train F1: 0.7446\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.5018\n",
      "Epoch 44:\n",
      "  Train Loss: 0.8431 | Train Acc: 0.7536 | Train F1: 0.7497\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4940\n",
      "Epoch 45:\n",
      "  Train Loss: 0.8352 | Train Acc: 0.7622 | Train F1: 0.7590\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5364\n",
      "Epoch 46:\n",
      "  Train Loss: 0.8276 | Train Acc: 0.7699 | Train F1: 0.7673\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5349\n",
      "Epoch 47:\n",
      "  Train Loss: 0.8218 | Train Acc: 0.7689 | Train F1: 0.7639\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5277\n",
      "Epoch 48:\n",
      "  Train Loss: 0.8107 | Train Acc: 0.7795 | Train F1: 0.7765\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5380\n",
      "Epoch 49:\n",
      "  Train Loss: 0.8033 | Train Acc: 0.7862 | Train F1: 0.7835\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5284\n",
      "Epoch 50:\n",
      "  Train Loss: 0.8003 | Train Acc: 0.7804 | Train F1: 0.7781\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5266\n",
      "Epoch 51:\n",
      "  Train Loss: 0.7885 | Train Acc: 0.7919 | Train F1: 0.7904\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5314\n",
      "Epoch 52:\n",
      "  Train Loss: 0.7811 | Train Acc: 0.7929 | Train F1: 0.7900\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5389\n",
      "Epoch 53:\n",
      "  Train Loss: 0.7735 | Train Acc: 0.8015 | Train F1: 0.7989\n",
      "  Val   Loss: nan | Val   Acc: 0.5247 | Val   F1: 0.5219\n",
      "Epoch 54:\n",
      "  Train Loss: 0.7653 | Train Acc: 0.8044 | Train F1: 0.8024\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5360\n",
      "Epoch 55:\n",
      "  Train Loss: 0.7610 | Train Acc: 0.8015 | Train F1: 0.7993\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5451\n",
      "Epoch 56:\n",
      "  Train Loss: 0.7520 | Train Acc: 0.8198 | Train F1: 0.8181\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5500\n",
      "Epoch 57:\n",
      "  Train Loss: 0.7454 | Train Acc: 0.8150 | Train F1: 0.8127\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5492\n",
      "Epoch 58:\n",
      "  Train Loss: 0.7404 | Train Acc: 0.8150 | Train F1: 0.8134\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5496\n",
      "Epoch 59:\n",
      "  Train Loss: 0.7320 | Train Acc: 0.8207 | Train F1: 0.8190\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5282\n",
      "Epoch 60:\n",
      "  Train Loss: 0.7273 | Train Acc: 0.8207 | Train F1: 0.8185\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5448\n",
      "Epoch 61:\n",
      "  Train Loss: 0.7181 | Train Acc: 0.8274 | Train F1: 0.8260\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5377\n",
      "Epoch 62:\n",
      "  Train Loss: 0.7134 | Train Acc: 0.8226 | Train F1: 0.8211\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5487\n",
      "Epoch 63:\n",
      "  Train Loss: 0.7056 | Train Acc: 0.8380 | Train F1: 0.8362\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5450\n",
      "Epoch 64:\n",
      "  Train Loss: 0.6967 | Train Acc: 0.8418 | Train F1: 0.8398\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5564\n",
      "Epoch 65:\n",
      "  Train Loss: 0.6906 | Train Acc: 0.8408 | Train F1: 0.8394\n",
      "  Val   Loss: nan | Val   Acc: 0.5695 | Val   F1: 0.5634\n",
      "Epoch 66:\n",
      "  Train Loss: 0.6814 | Train Acc: 0.8533 | Train F1: 0.8517\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5615\n",
      "Epoch 67:\n",
      "  Train Loss: 0.6751 | Train Acc: 0.8581 | Train F1: 0.8570\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5684\n",
      "Epoch 68:\n",
      "  Train Loss: 0.6684 | Train Acc: 0.8562 | Train F1: 0.8546\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5680\n",
      "Epoch 69:\n",
      "  Train Loss: 0.6645 | Train Acc: 0.8562 | Train F1: 0.8549\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5544\n",
      "Epoch 70:\n",
      "  Train Loss: 0.6590 | Train Acc: 0.8581 | Train F1: 0.8571\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5858\n",
      "Epoch 71:\n",
      "  Train Loss: 0.6524 | Train Acc: 0.8744 | Train F1: 0.8732\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5715\n",
      "Epoch 72:\n",
      "  Train Loss: 0.6433 | Train Acc: 0.8830 | Train F1: 0.8820\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5790\n",
      "Epoch 73:\n",
      "  Train Loss: 0.6375 | Train Acc: 0.8744 | Train F1: 0.8732\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5815\n",
      "Epoch 74:\n",
      "  Train Loss: 0.6301 | Train Acc: 0.8802 | Train F1: 0.8791\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5578\n",
      "Epoch 75:\n",
      "  Train Loss: 0.6259 | Train Acc: 0.8869 | Train F1: 0.8861\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6054\n",
      "Epoch 76:\n",
      "  Train Loss: 0.6170 | Train Acc: 0.8859 | Train F1: 0.8851\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6029\n",
      "Epoch 77:\n",
      "  Train Loss: 0.6117 | Train Acc: 0.8936 | Train F1: 0.8929\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5890\n",
      "Epoch 78:\n",
      "  Train Loss: 0.6046 | Train Acc: 0.8974 | Train F1: 0.8966\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5831\n",
      "Epoch 79:\n",
      "  Train Loss: 0.5979 | Train Acc: 0.9051 | Train F1: 0.9039\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5985\n",
      "Epoch 80:\n",
      "  Train Loss: 0.5923 | Train Acc: 0.9089 | Train F1: 0.9086\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5896\n",
      "Epoch 81:\n",
      "  Train Loss: 0.5883 | Train Acc: 0.9080 | Train F1: 0.9072\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5907\n",
      "Epoch 82:\n",
      "  Train Loss: 0.5798 | Train Acc: 0.9147 | Train F1: 0.9143\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5940\n",
      "Epoch 83:\n",
      "  Train Loss: 0.5737 | Train Acc: 0.9166 | Train F1: 0.9162\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6083\n",
      "Epoch 84:\n",
      "  Train Loss: 0.5688 | Train Acc: 0.9128 | Train F1: 0.9122\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6014\n",
      "Epoch 85:\n",
      "  Train Loss: 0.5620 | Train Acc: 0.9185 | Train F1: 0.9180\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6005\n",
      "Epoch 86:\n",
      "  Train Loss: 0.5569 | Train Acc: 0.9233 | Train F1: 0.9227\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6059\n",
      "Epoch 87:\n",
      "  Train Loss: 0.5523 | Train Acc: 0.9223 | Train F1: 0.9217\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5976\n",
      "Epoch 88:\n",
      "  Train Loss: 0.5454 | Train Acc: 0.9262 | Train F1: 0.9258\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5974\n",
      "Epoch 89:\n",
      "  Train Loss: 0.5452 | Train Acc: 0.9204 | Train F1: 0.9200\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5861\n",
      "Epoch 90:\n",
      "  Train Loss: 0.5365 | Train Acc: 0.9367 | Train F1: 0.9365\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6057\n",
      "Epoch 91:\n",
      "  Train Loss: 0.5336 | Train Acc: 0.9338 | Train F1: 0.9336\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6041\n",
      "Epoch 92:\n",
      "  Train Loss: 0.5267 | Train Acc: 0.9367 | Train F1: 0.9363\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6147\n",
      "Epoch 93:\n",
      "  Train Loss: 0.5186 | Train Acc: 0.9444 | Train F1: 0.9442\n",
      "  Val   Loss: nan | Val   Acc: 0.5919 | Val   F1: 0.5909\n",
      "Epoch 94:\n",
      "  Train Loss: 0.5133 | Train Acc: 0.9453 | Train F1: 0.9452\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6062\n",
      "Epoch 95:\n",
      "  Train Loss: 0.5119 | Train Acc: 0.9406 | Train F1: 0.9403\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5997\n",
      "Epoch 96:\n",
      "  Train Loss: 0.5046 | Train Acc: 0.9444 | Train F1: 0.9442\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6080\n",
      "Epoch 97:\n",
      "  Train Loss: 0.4978 | Train Acc: 0.9482 | Train F1: 0.9481\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5971\n",
      "Epoch 98:\n",
      "  Train Loss: 0.4961 | Train Acc: 0.9473 | Train F1: 0.9471\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6081\n",
      "Epoch 99:\n",
      "  Train Loss: 0.4926 | Train Acc: 0.9530 | Train F1: 0.9529\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6266\n",
      "Epoch 100:\n",
      "  Train Loss: 0.4860 | Train Acc: 0.9530 | Train F1: 0.9528\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6217\n",
      "Epoch 101:\n",
      "  Train Loss: 0.4845 | Train Acc: 0.9530 | Train F1: 0.9529\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.6021\n",
      "Epoch 102:\n",
      "  Train Loss: 0.4758 | Train Acc: 0.9549 | Train F1: 0.9548\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6157\n",
      "Epoch 103:\n",
      "  Train Loss: 0.4760 | Train Acc: 0.9559 | Train F1: 0.9558\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6193\n",
      "Epoch 104:\n",
      "  Train Loss: 0.4671 | Train Acc: 0.9588 | Train F1: 0.9585\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6205\n",
      "Epoch 105:\n",
      "  Train Loss: 0.4627 | Train Acc: 0.9607 | Train F1: 0.9605\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5956\n",
      "Epoch 106:\n",
      "  Train Loss: 0.4607 | Train Acc: 0.9645 | Train F1: 0.9643\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6196\n",
      "Epoch 107:\n",
      "  Train Loss: 0.4541 | Train Acc: 0.9636 | Train F1: 0.9633\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6234\n",
      "Epoch 108:\n",
      "  Train Loss: 0.4518 | Train Acc: 0.9674 | Train F1: 0.9672\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6196\n",
      "Epoch 109:\n",
      "  Train Loss: 0.4451 | Train Acc: 0.9722 | Train F1: 0.9721\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6245\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=1e-05, weight_decay=0.01 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3878 | Train Acc: 0.2531 | Train F1: 0.1732\n",
      "  Val   Loss: nan | Val   Acc: 0.2915 | Val   F1: 0.1978\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3847 | Train Acc: 0.2991 | Train F1: 0.2078\n",
      "  Val   Loss: nan | Val   Acc: 0.3094 | Val   F1: 0.2063\n",
      "Epoch 3:\n",
      "  Train Loss: 1.3810 | Train Acc: 0.3346 | Train F1: 0.2507\n",
      "  Val   Loss: nan | Val   Acc: 0.2780 | Val   F1: 0.2242\n",
      "Epoch 4:\n",
      "  Train Loss: 1.3760 | Train Acc: 0.3835 | Train F1: 0.3277\n",
      "  Val   Loss: nan | Val   Acc: 0.2735 | Val   F1: 0.2451\n",
      "Epoch 5:\n",
      "  Train Loss: 1.3693 | Train Acc: 0.3902 | Train F1: 0.3193\n",
      "  Val   Loss: nan | Val   Acc: 0.2870 | Val   F1: 0.2547\n",
      "Epoch 6:\n",
      "  Train Loss: 1.3593 | Train Acc: 0.4238 | Train F1: 0.3570\n",
      "  Val   Loss: nan | Val   Acc: 0.3408 | Val   F1: 0.2959\n",
      "Epoch 7:\n",
      "  Train Loss: 1.3453 | Train Acc: 0.4372 | Train F1: 0.3723\n",
      "  Val   Loss: nan | Val   Acc: 0.3049 | Val   F1: 0.2703\n",
      "Epoch 8:\n",
      "  Train Loss: 1.3279 | Train Acc: 0.4506 | Train F1: 0.3833\n",
      "  Val   Loss: nan | Val   Acc: 0.3453 | Val   F1: 0.3083\n",
      "Epoch 9:\n",
      "  Train Loss: 1.3047 | Train Acc: 0.4535 | Train F1: 0.3869\n",
      "  Val   Loss: nan | Val   Acc: 0.3632 | Val   F1: 0.3243\n",
      "Epoch 10:\n",
      "  Train Loss: 1.2796 | Train Acc: 0.4727 | Train F1: 0.4043\n",
      "  Val   Loss: nan | Val   Acc: 0.3901 | Val   F1: 0.3436\n",
      "Epoch 11:\n",
      "  Train Loss: 1.2549 | Train Acc: 0.4813 | Train F1: 0.4146\n",
      "  Val   Loss: nan | Val   Acc: 0.3946 | Val   F1: 0.3527\n",
      "Epoch 12:\n",
      "  Train Loss: 1.2322 | Train Acc: 0.4880 | Train F1: 0.4232\n",
      "  Val   Loss: nan | Val   Acc: 0.3991 | Val   F1: 0.3605\n",
      "Epoch 13:\n",
      "  Train Loss: 1.2113 | Train Acc: 0.4966 | Train F1: 0.4317\n",
      "  Val   Loss: nan | Val   Acc: 0.4036 | Val   F1: 0.3648\n",
      "Epoch 14:\n",
      "  Train Loss: 1.1880 | Train Acc: 0.5129 | Train F1: 0.4461\n",
      "  Val   Loss: nan | Val   Acc: 0.4036 | Val   F1: 0.3649\n",
      "Epoch 15:\n",
      "  Train Loss: 1.1686 | Train Acc: 0.5273 | Train F1: 0.4643\n",
      "  Val   Loss: nan | Val   Acc: 0.3946 | Val   F1: 0.3621\n",
      "Epoch 16:\n",
      "  Train Loss: 1.1531 | Train Acc: 0.5427 | Train F1: 0.4912\n",
      "  Val   Loss: nan | Val   Acc: 0.4170 | Val   F1: 0.3790\n",
      "Epoch 17:\n",
      "  Train Loss: 1.1341 | Train Acc: 0.5542 | Train F1: 0.5074\n",
      "  Val   Loss: nan | Val   Acc: 0.4395 | Val   F1: 0.4078\n",
      "Epoch 18:\n",
      "  Train Loss: 1.1177 | Train Acc: 0.5666 | Train F1: 0.5217\n",
      "  Val   Loss: nan | Val   Acc: 0.4126 | Val   F1: 0.3842\n",
      "Epoch 19:\n",
      "  Train Loss: 1.1014 | Train Acc: 0.5781 | Train F1: 0.5384\n",
      "  Val   Loss: nan | Val   Acc: 0.4170 | Val   F1: 0.3876\n",
      "Epoch 20:\n",
      "  Train Loss: 1.0863 | Train Acc: 0.5877 | Train F1: 0.5483\n",
      "  Val   Loss: nan | Val   Acc: 0.4395 | Val   F1: 0.4059\n",
      "Epoch 21:\n",
      "  Train Loss: 1.0744 | Train Acc: 0.5810 | Train F1: 0.5362\n",
      "  Val   Loss: nan | Val   Acc: 0.4529 | Val   F1: 0.4209\n",
      "Epoch 22:\n",
      "  Train Loss: 1.0586 | Train Acc: 0.6088 | Train F1: 0.5765\n",
      "  Val   Loss: nan | Val   Acc: 0.4619 | Val   F1: 0.4242\n",
      "Epoch 23:\n",
      "  Train Loss: 1.0470 | Train Acc: 0.6117 | Train F1: 0.5792\n",
      "  Val   Loss: nan | Val   Acc: 0.4619 | Val   F1: 0.4283\n",
      "Epoch 24:\n",
      "  Train Loss: 1.0318 | Train Acc: 0.6242 | Train F1: 0.5913\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4570\n",
      "Epoch 25:\n",
      "  Train Loss: 1.0250 | Train Acc: 0.6213 | Train F1: 0.5869\n",
      "  Val   Loss: nan | Val   Acc: 0.4709 | Val   F1: 0.4454\n",
      "Epoch 26:\n",
      "  Train Loss: 1.0101 | Train Acc: 0.6395 | Train F1: 0.6093\n",
      "  Val   Loss: nan | Val   Acc: 0.4933 | Val   F1: 0.4713\n",
      "Epoch 27:\n",
      "  Train Loss: 1.0015 | Train Acc: 0.6462 | Train F1: 0.6157\n",
      "  Val   Loss: nan | Val   Acc: 0.4888 | Val   F1: 0.4701\n",
      "Epoch 28:\n",
      "  Train Loss: 0.9869 | Train Acc: 0.6577 | Train F1: 0.6350\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4658\n",
      "Epoch 29:\n",
      "  Train Loss: 0.9777 | Train Acc: 0.6577 | Train F1: 0.6325\n",
      "  Val   Loss: nan | Val   Acc: 0.4888 | Val   F1: 0.4691\n",
      "Epoch 30:\n",
      "  Train Loss: 0.9687 | Train Acc: 0.6663 | Train F1: 0.6399\n",
      "  Val   Loss: nan | Val   Acc: 0.4933 | Val   F1: 0.4760\n",
      "Epoch 31:\n",
      "  Train Loss: 0.9579 | Train Acc: 0.6836 | Train F1: 0.6593\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4663\n",
      "Epoch 32:\n",
      "  Train Loss: 0.9490 | Train Acc: 0.6740 | Train F1: 0.6443\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4682\n",
      "Epoch 33:\n",
      "  Train Loss: 0.9404 | Train Acc: 0.6846 | Train F1: 0.6655\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.4988\n",
      "Epoch 34:\n",
      "  Train Loss: 0.9314 | Train Acc: 0.6874 | Train F1: 0.6640\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4702\n",
      "Epoch 35:\n",
      "  Train Loss: 0.9223 | Train Acc: 0.6961 | Train F1: 0.6690\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.4922\n",
      "Epoch 36:\n",
      "  Train Loss: 0.9150 | Train Acc: 0.7076 | Train F1: 0.6889\n",
      "  Val   Loss: nan | Val   Acc: 0.5022 | Val   F1: 0.4925\n",
      "Epoch 37:\n",
      "  Train Loss: 0.9086 | Train Acc: 0.7057 | Train F1: 0.6896\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4823\n",
      "Epoch 38:\n",
      "  Train Loss: 0.8999 | Train Acc: 0.7152 | Train F1: 0.6941\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4872\n",
      "Epoch 39:\n",
      "  Train Loss: 0.8897 | Train Acc: 0.7248 | Train F1: 0.7098\n",
      "  Val   Loss: nan | Val   Acc: 0.5112 | Val   F1: 0.4981\n",
      "Epoch 40:\n",
      "  Train Loss: 0.8851 | Train Acc: 0.7258 | Train F1: 0.7095\n",
      "  Val   Loss: nan | Val   Acc: 0.5202 | Val   F1: 0.5009\n",
      "Epoch 41:\n",
      "  Train Loss: 0.8765 | Train Acc: 0.7296 | Train F1: 0.7134\n",
      "  Val   Loss: nan | Val   Acc: 0.5112 | Val   F1: 0.4992\n",
      "Epoch 42:\n",
      "  Train Loss: 0.8686 | Train Acc: 0.7392 | Train F1: 0.7251\n",
      "  Val   Loss: nan | Val   Acc: 0.5022 | Val   F1: 0.4837\n",
      "Epoch 43:\n",
      "  Train Loss: 0.8603 | Train Acc: 0.7440 | Train F1: 0.7312\n",
      "  Val   Loss: nan | Val   Acc: 0.5202 | Val   F1: 0.5051\n",
      "Epoch 44:\n",
      "  Train Loss: 0.8564 | Train Acc: 0.7498 | Train F1: 0.7391\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.5021\n",
      "Epoch 45:\n",
      "  Train Loss: 0.8494 | Train Acc: 0.7565 | Train F1: 0.7465\n",
      "  Val   Loss: nan | Val   Acc: 0.5247 | Val   F1: 0.5130\n",
      "Epoch 46:\n",
      "  Train Loss: 0.8412 | Train Acc: 0.7613 | Train F1: 0.7481\n",
      "  Val   Loss: nan | Val   Acc: 0.5112 | Val   F1: 0.5063\n",
      "Epoch 47:\n",
      "  Train Loss: 0.8364 | Train Acc: 0.7488 | Train F1: 0.7406\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.4994\n",
      "Epoch 48:\n",
      "  Train Loss: 0.8286 | Train Acc: 0.7670 | Train F1: 0.7572\n",
      "  Val   Loss: nan | Val   Acc: 0.5112 | Val   F1: 0.5022\n",
      "Epoch 49:\n",
      "  Train Loss: 0.8241 | Train Acc: 0.7670 | Train F1: 0.7565\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.5073\n",
      "Epoch 50:\n",
      "  Train Loss: 0.8174 | Train Acc: 0.7795 | Train F1: 0.7728\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5256\n",
      "Epoch 51:\n",
      "  Train Loss: 0.8067 | Train Acc: 0.7833 | Train F1: 0.7759\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5449\n",
      "Epoch 52:\n",
      "  Train Loss: 0.8037 | Train Acc: 0.7795 | Train F1: 0.7719\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5231\n",
      "Epoch 53:\n",
      "  Train Loss: 0.7964 | Train Acc: 0.7891 | Train F1: 0.7825\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5408\n",
      "Epoch 54:\n",
      "  Train Loss: 0.7876 | Train Acc: 0.7881 | Train F1: 0.7806\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4959\n",
      "Epoch 55:\n",
      "  Train Loss: 0.7810 | Train Acc: 0.7958 | Train F1: 0.7897\n",
      "  Val   Loss: nan | Val   Acc: 0.5202 | Val   F1: 0.5131\n",
      "Epoch 56:\n",
      "  Train Loss: 0.7741 | Train Acc: 0.7996 | Train F1: 0.7923\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5277\n",
      "Epoch 57:\n",
      "  Train Loss: 0.7671 | Train Acc: 0.8044 | Train F1: 0.7979\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5682\n",
      "Epoch 58:\n",
      "  Train Loss: 0.7642 | Train Acc: 0.8025 | Train F1: 0.7953\n",
      "  Val   Loss: nan | Val   Acc: 0.5157 | Val   F1: 0.5053\n",
      "Epoch 59:\n",
      "  Train Loss: 0.7543 | Train Acc: 0.8150 | Train F1: 0.8089\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5434\n",
      "Epoch 60:\n",
      "  Train Loss: 0.7486 | Train Acc: 0.8169 | Train F1: 0.8110\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5379\n",
      "Epoch 61:\n",
      "  Train Loss: 0.7410 | Train Acc: 0.8236 | Train F1: 0.8191\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5269\n",
      "Epoch 62:\n",
      "  Train Loss: 0.7364 | Train Acc: 0.8217 | Train F1: 0.8168\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5405\n",
      "Epoch 63:\n",
      "  Train Loss: 0.7295 | Train Acc: 0.8265 | Train F1: 0.8231\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5446\n",
      "Epoch 64:\n",
      "  Train Loss: 0.7277 | Train Acc: 0.8255 | Train F1: 0.8229\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5435\n",
      "Epoch 65:\n",
      "  Train Loss: 0.7182 | Train Acc: 0.8341 | Train F1: 0.8306\n",
      "  Val   Loss: nan | Val   Acc: 0.5381 | Val   F1: 0.5388\n",
      "Epoch 66:\n",
      "  Train Loss: 0.7101 | Train Acc: 0.8370 | Train F1: 0.8332\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5506\n",
      "Epoch 67:\n",
      "  Train Loss: 0.7052 | Train Acc: 0.8303 | Train F1: 0.8269\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5414\n",
      "Early stopping triggered!\n",
      "\n",
      "==== Trying lr=1e-05, weight_decay=0.05 ====\n",
      "Epoch 1:\n",
      "  Train Loss: 1.3923 | Train Acc: 0.2359 | Train F1: 0.1945\n",
      "  Val   Loss: nan | Val   Acc: 0.2915 | Val   F1: 0.2443\n",
      "Epoch 2:\n",
      "  Train Loss: 1.3883 | Train Acc: 0.2819 | Train F1: 0.2434\n",
      "  Val   Loss: nan | Val   Acc: 0.2870 | Val   F1: 0.2327\n",
      "Epoch 3:\n",
      "  Train Loss: 1.3849 | Train Acc: 0.3269 | Train F1: 0.2513\n",
      "  Val   Loss: nan | Val   Acc: 0.3094 | Val   F1: 0.2222\n",
      "Epoch 4:\n",
      "  Train Loss: 1.3820 | Train Acc: 0.3423 | Train F1: 0.2467\n",
      "  Val   Loss: nan | Val   Acc: 0.3363 | Val   F1: 0.2506\n",
      "Epoch 5:\n",
      "  Train Loss: 1.3777 | Train Acc: 0.3384 | Train F1: 0.2531\n",
      "  Val   Loss: nan | Val   Acc: 0.3498 | Val   F1: 0.2567\n",
      "Epoch 6:\n",
      "  Train Loss: 1.3719 | Train Acc: 0.3720 | Train F1: 0.2984\n",
      "  Val   Loss: nan | Val   Acc: 0.3812 | Val   F1: 0.3352\n",
      "Epoch 7:\n",
      "  Train Loss: 1.3622 | Train Acc: 0.4094 | Train F1: 0.3612\n",
      "  Val   Loss: nan | Val   Acc: 0.3453 | Val   F1: 0.3106\n",
      "Epoch 8:\n",
      "  Train Loss: 1.3476 | Train Acc: 0.4132 | Train F1: 0.3692\n",
      "  Val   Loss: nan | Val   Acc: 0.3767 | Val   F1: 0.3377\n",
      "Epoch 9:\n",
      "  Train Loss: 1.3291 | Train Acc: 0.4372 | Train F1: 0.3905\n",
      "  Val   Loss: nan | Val   Acc: 0.3498 | Val   F1: 0.3101\n",
      "Epoch 10:\n",
      "  Train Loss: 1.3075 | Train Acc: 0.4564 | Train F1: 0.4263\n",
      "  Val   Loss: nan | Val   Acc: 0.3498 | Val   F1: 0.3014\n",
      "Epoch 11:\n",
      "  Train Loss: 1.2866 | Train Acc: 0.4679 | Train F1: 0.4391\n",
      "  Val   Loss: nan | Val   Acc: 0.3857 | Val   F1: 0.3602\n",
      "Epoch 12:\n",
      "  Train Loss: 1.2663 | Train Acc: 0.4928 | Train F1: 0.4753\n",
      "  Val   Loss: nan | Val   Acc: 0.3857 | Val   F1: 0.3681\n",
      "Epoch 13:\n",
      "  Train Loss: 1.2437 | Train Acc: 0.4976 | Train F1: 0.4707\n",
      "  Val   Loss: nan | Val   Acc: 0.4081 | Val   F1: 0.3873\n",
      "Epoch 14:\n",
      "  Train Loss: 1.2246 | Train Acc: 0.5091 | Train F1: 0.4901\n",
      "  Val   Loss: nan | Val   Acc: 0.3946 | Val   F1: 0.3755\n",
      "Epoch 15:\n",
      "  Train Loss: 1.2029 | Train Acc: 0.5139 | Train F1: 0.4962\n",
      "  Val   Loss: nan | Val   Acc: 0.4260 | Val   F1: 0.4093\n",
      "Epoch 16:\n",
      "  Train Loss: 1.1850 | Train Acc: 0.5312 | Train F1: 0.5189\n",
      "  Val   Loss: nan | Val   Acc: 0.3991 | Val   F1: 0.3818\n",
      "Epoch 17:\n",
      "  Train Loss: 1.1673 | Train Acc: 0.5417 | Train F1: 0.5217\n",
      "  Val   Loss: nan | Val   Acc: 0.3991 | Val   F1: 0.3795\n",
      "Epoch 18:\n",
      "  Train Loss: 1.1459 | Train Acc: 0.5618 | Train F1: 0.5501\n",
      "  Val   Loss: nan | Val   Acc: 0.4126 | Val   F1: 0.3963\n",
      "Epoch 19:\n",
      "  Train Loss: 1.1283 | Train Acc: 0.5657 | Train F1: 0.5503\n",
      "  Val   Loss: nan | Val   Acc: 0.3991 | Val   F1: 0.3889\n",
      "Epoch 20:\n",
      "  Train Loss: 1.1151 | Train Acc: 0.5686 | Train F1: 0.5564\n",
      "  Val   Loss: nan | Val   Acc: 0.4081 | Val   F1: 0.3987\n",
      "Epoch 21:\n",
      "  Train Loss: 1.0941 | Train Acc: 0.6059 | Train F1: 0.5915\n",
      "  Val   Loss: nan | Val   Acc: 0.4350 | Val   F1: 0.4284\n",
      "Epoch 22:\n",
      "  Train Loss: 1.0774 | Train Acc: 0.6021 | Train F1: 0.5929\n",
      "  Val   Loss: nan | Val   Acc: 0.4484 | Val   F1: 0.4416\n",
      "Epoch 23:\n",
      "  Train Loss: 1.0630 | Train Acc: 0.6270 | Train F1: 0.6194\n",
      "  Val   Loss: nan | Val   Acc: 0.4350 | Val   F1: 0.4156\n",
      "Epoch 24:\n",
      "  Train Loss: 1.0456 | Train Acc: 0.6376 | Train F1: 0.6219\n",
      "  Val   Loss: nan | Val   Acc: 0.4664 | Val   F1: 0.4514\n",
      "Epoch 25:\n",
      "  Train Loss: 1.0325 | Train Acc: 0.6500 | Train F1: 0.6418\n",
      "  Val   Loss: nan | Val   Acc: 0.4395 | Val   F1: 0.4274\n",
      "Epoch 26:\n",
      "  Train Loss: 1.0116 | Train Acc: 0.6520 | Train F1: 0.6414\n",
      "  Val   Loss: nan | Val   Acc: 0.4484 | Val   F1: 0.4450\n",
      "Epoch 27:\n",
      "  Train Loss: 1.0030 | Train Acc: 0.6520 | Train F1: 0.6416\n",
      "  Val   Loss: nan | Val   Acc: 0.4709 | Val   F1: 0.4654\n",
      "Epoch 28:\n",
      "  Train Loss: 0.9851 | Train Acc: 0.6702 | Train F1: 0.6601\n",
      "  Val   Loss: nan | Val   Acc: 0.4709 | Val   F1: 0.4673\n",
      "Epoch 29:\n",
      "  Train Loss: 0.9725 | Train Acc: 0.6884 | Train F1: 0.6816\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4691\n",
      "Epoch 30:\n",
      "  Train Loss: 0.9593 | Train Acc: 0.6874 | Train F1: 0.6783\n",
      "  Val   Loss: nan | Val   Acc: 0.4395 | Val   F1: 0.4331\n",
      "Epoch 31:\n",
      "  Train Loss: 0.9456 | Train Acc: 0.7066 | Train F1: 0.6967\n",
      "  Val   Loss: nan | Val   Acc: 0.4798 | Val   F1: 0.4741\n",
      "Epoch 32:\n",
      "  Train Loss: 0.9359 | Train Acc: 0.7076 | Train F1: 0.7008\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4868\n",
      "Epoch 33:\n",
      "  Train Loss: 0.9213 | Train Acc: 0.7133 | Train F1: 0.7046\n",
      "  Val   Loss: nan | Val   Acc: 0.4484 | Val   F1: 0.4406\n",
      "Epoch 34:\n",
      "  Train Loss: 0.9145 | Train Acc: 0.7124 | Train F1: 0.7041\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4720\n",
      "Epoch 35:\n",
      "  Train Loss: 0.9013 | Train Acc: 0.7152 | Train F1: 0.7087\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4837\n",
      "Epoch 36:\n",
      "  Train Loss: 0.8936 | Train Acc: 0.7277 | Train F1: 0.7221\n",
      "  Val   Loss: nan | Val   Acc: 0.4709 | Val   F1: 0.4610\n",
      "Epoch 37:\n",
      "  Train Loss: 0.8855 | Train Acc: 0.7344 | Train F1: 0.7286\n",
      "  Val   Loss: nan | Val   Acc: 0.5247 | Val   F1: 0.5177\n",
      "Epoch 38:\n",
      "  Train Loss: 0.8725 | Train Acc: 0.7440 | Train F1: 0.7360\n",
      "  Val   Loss: nan | Val   Acc: 0.4933 | Val   F1: 0.4907\n",
      "Epoch 39:\n",
      "  Train Loss: 0.8628 | Train Acc: 0.7450 | Train F1: 0.7409\n",
      "  Val   Loss: nan | Val   Acc: 0.4843 | Val   F1: 0.4726\n",
      "Epoch 40:\n",
      "  Train Loss: 0.8554 | Train Acc: 0.7507 | Train F1: 0.7436\n",
      "  Val   Loss: nan | Val   Acc: 0.5202 | Val   F1: 0.5105\n",
      "Epoch 41:\n",
      "  Train Loss: 0.8422 | Train Acc: 0.7517 | Train F1: 0.7444\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5368\n",
      "Epoch 42:\n",
      "  Train Loss: 0.8393 | Train Acc: 0.7459 | Train F1: 0.7407\n",
      "  Val   Loss: nan | Val   Acc: 0.4978 | Val   F1: 0.4951\n",
      "Epoch 43:\n",
      "  Train Loss: 0.8302 | Train Acc: 0.7680 | Train F1: 0.7641\n",
      "  Val   Loss: nan | Val   Acc: 0.5067 | Val   F1: 0.5055\n",
      "Epoch 44:\n",
      "  Train Loss: 0.8177 | Train Acc: 0.7785 | Train F1: 0.7739\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5274\n",
      "Epoch 45:\n",
      "  Train Loss: 0.8126 | Train Acc: 0.7747 | Train F1: 0.7709\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5283\n",
      "Epoch 46:\n",
      "  Train Loss: 0.8029 | Train Acc: 0.7804 | Train F1: 0.7768\n",
      "  Val   Loss: nan | Val   Acc: 0.5291 | Val   F1: 0.5226\n",
      "Epoch 47:\n",
      "  Train Loss: 0.7943 | Train Acc: 0.7919 | Train F1: 0.7874\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5402\n",
      "Epoch 48:\n",
      "  Train Loss: 0.7888 | Train Acc: 0.7910 | Train F1: 0.7874\n",
      "  Val   Loss: nan | Val   Acc: 0.5516 | Val   F1: 0.5451\n",
      "Epoch 49:\n",
      "  Train Loss: 0.7786 | Train Acc: 0.7967 | Train F1: 0.7933\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5554\n",
      "Epoch 50:\n",
      "  Train Loss: 0.7736 | Train Acc: 0.7977 | Train F1: 0.7954\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5613\n",
      "Epoch 51:\n",
      "  Train Loss: 0.7638 | Train Acc: 0.8035 | Train F1: 0.8003\n",
      "  Val   Loss: nan | Val   Acc: 0.5561 | Val   F1: 0.5512\n",
      "Epoch 52:\n",
      "  Train Loss: 0.7564 | Train Acc: 0.8102 | Train F1: 0.8075\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5433\n",
      "Epoch 53:\n",
      "  Train Loss: 0.7490 | Train Acc: 0.8130 | Train F1: 0.8098\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5608\n",
      "Epoch 54:\n",
      "  Train Loss: 0.7434 | Train Acc: 0.8130 | Train F1: 0.8108\n",
      "  Val   Loss: nan | Val   Acc: 0.5426 | Val   F1: 0.5406\n",
      "Epoch 55:\n",
      "  Train Loss: 0.7348 | Train Acc: 0.8188 | Train F1: 0.8167\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5756\n",
      "Epoch 56:\n",
      "  Train Loss: 0.7310 | Train Acc: 0.8188 | Train F1: 0.8160\n",
      "  Val   Loss: nan | Val   Acc: 0.5471 | Val   F1: 0.5418\n",
      "Epoch 57:\n",
      "  Train Loss: 0.7209 | Train Acc: 0.8303 | Train F1: 0.8279\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5550\n",
      "Epoch 58:\n",
      "  Train Loss: 0.7133 | Train Acc: 0.8341 | Train F1: 0.8319\n",
      "  Val   Loss: nan | Val   Acc: 0.5336 | Val   F1: 0.5303\n",
      "Epoch 59:\n",
      "  Train Loss: 0.7076 | Train Acc: 0.8380 | Train F1: 0.8363\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5711\n",
      "Epoch 60:\n",
      "  Train Loss: 0.7021 | Train Acc: 0.8437 | Train F1: 0.8415\n",
      "  Val   Loss: nan | Val   Acc: 0.5650 | Val   F1: 0.5626\n",
      "Epoch 61:\n",
      "  Train Loss: 0.6956 | Train Acc: 0.8476 | Train F1: 0.8456\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5642\n",
      "Epoch 62:\n",
      "  Train Loss: 0.6876 | Train Acc: 0.8514 | Train F1: 0.8497\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5547\n",
      "Epoch 63:\n",
      "  Train Loss: 0.6828 | Train Acc: 0.8504 | Train F1: 0.8480\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5731\n",
      "Epoch 64:\n",
      "  Train Loss: 0.6739 | Train Acc: 0.8619 | Train F1: 0.8606\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5820\n",
      "Epoch 65:\n",
      "  Train Loss: 0.6646 | Train Acc: 0.8619 | Train F1: 0.8603\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5781\n",
      "Epoch 66:\n",
      "  Train Loss: 0.6607 | Train Acc: 0.8658 | Train F1: 0.8646\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5771\n",
      "Epoch 67:\n",
      "  Train Loss: 0.6558 | Train Acc: 0.8639 | Train F1: 0.8621\n",
      "  Val   Loss: nan | Val   Acc: 0.5740 | Val   F1: 0.5644\n",
      "Epoch 68:\n",
      "  Train Loss: 0.6498 | Train Acc: 0.8667 | Train F1: 0.8659\n",
      "  Val   Loss: nan | Val   Acc: 0.5605 | Val   F1: 0.5597\n",
      "Epoch 69:\n",
      "  Train Loss: 0.6464 | Train Acc: 0.8744 | Train F1: 0.8728\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5772\n",
      "Epoch 70:\n",
      "  Train Loss: 0.6385 | Train Acc: 0.8782 | Train F1: 0.8768\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5738\n",
      "Epoch 71:\n",
      "  Train Loss: 0.6316 | Train Acc: 0.8773 | Train F1: 0.8759\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5782\n",
      "Epoch 72:\n",
      "  Train Loss: 0.6279 | Train Acc: 0.8869 | Train F1: 0.8854\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5831\n",
      "Epoch 73:\n",
      "  Train Loss: 0.6196 | Train Acc: 0.8859 | Train F1: 0.8846\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5764\n",
      "Epoch 74:\n",
      "  Train Loss: 0.6146 | Train Acc: 0.8878 | Train F1: 0.8867\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5807\n",
      "Epoch 75:\n",
      "  Train Loss: 0.6096 | Train Acc: 0.8945 | Train F1: 0.8934\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5708\n",
      "Epoch 76:\n",
      "  Train Loss: 0.6054 | Train Acc: 0.8917 | Train F1: 0.8907\n",
      "  Val   Loss: nan | Val   Acc: 0.5874 | Val   F1: 0.5817\n",
      "Epoch 77:\n",
      "  Train Loss: 0.6000 | Train Acc: 0.8926 | Train F1: 0.8913\n",
      "  Val   Loss: nan | Val   Acc: 0.5785 | Val   F1: 0.5748\n",
      "Epoch 78:\n",
      "  Train Loss: 0.5922 | Train Acc: 0.9003 | Train F1: 0.8992\n",
      "  Val   Loss: nan | Val   Acc: 0.5830 | Val   F1: 0.5786\n",
      "Epoch 79:\n",
      "  Train Loss: 0.5869 | Train Acc: 0.9012 | Train F1: 0.9004\n",
      "  Val   Loss: nan | Val   Acc: 0.6054 | Val   F1: 0.5975\n",
      "Epoch 80:\n",
      "  Train Loss: 0.5800 | Train Acc: 0.9012 | Train F1: 0.9001\n",
      "  Val   Loss: nan | Val   Acc: 0.5964 | Val   F1: 0.5936\n",
      "Epoch 81:\n",
      "  Train Loss: 0.5744 | Train Acc: 0.9108 | Train F1: 0.9096\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5923\n",
      "Epoch 82:\n",
      "  Train Loss: 0.5685 | Train Acc: 0.9147 | Train F1: 0.9137\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5911\n",
      "Epoch 83:\n",
      "  Train Loss: 0.5643 | Train Acc: 0.9156 | Train F1: 0.9148\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5941\n",
      "Epoch 84:\n",
      "  Train Loss: 0.5564 | Train Acc: 0.9214 | Train F1: 0.9203\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5912\n",
      "Epoch 85:\n",
      "  Train Loss: 0.5513 | Train Acc: 0.9185 | Train F1: 0.9175\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6136\n",
      "Epoch 86:\n",
      "  Train Loss: 0.5441 | Train Acc: 0.9262 | Train F1: 0.9254\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6081\n",
      "Epoch 87:\n",
      "  Train Loss: 0.5403 | Train Acc: 0.9319 | Train F1: 0.9311\n",
      "  Val   Loss: nan | Val   Acc: 0.6009 | Val   F1: 0.5960\n",
      "Epoch 88:\n",
      "  Train Loss: 0.5364 | Train Acc: 0.9271 | Train F1: 0.9263\n",
      "  Val   Loss: nan | Val   Acc: 0.6188 | Val   F1: 0.6125\n",
      "Epoch 89:\n",
      "  Train Loss: 0.5300 | Train Acc: 0.9310 | Train F1: 0.9301\n",
      "  Val   Loss: nan | Val   Acc: 0.6099 | Val   F1: 0.6041\n",
      "Epoch 90:\n",
      "  Train Loss: 0.5254 | Train Acc: 0.9348 | Train F1: 0.9339\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6256\n",
      "Epoch 91:\n",
      "  Train Loss: 0.5222 | Train Acc: 0.9386 | Train F1: 0.9378\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6288\n",
      "Epoch 92:\n",
      "  Train Loss: 0.5159 | Train Acc: 0.9415 | Train F1: 0.9408\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6226\n",
      "Epoch 93:\n",
      "  Train Loss: 0.5093 | Train Acc: 0.9473 | Train F1: 0.9468\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6203\n",
      "Epoch 94:\n",
      "  Train Loss: 0.5039 | Train Acc: 0.9549 | Train F1: 0.9546\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6219\n",
      "Epoch 95:\n",
      "  Train Loss: 0.4993 | Train Acc: 0.9578 | Train F1: 0.9574\n",
      "  Val   Loss: nan | Val   Acc: 0.6143 | Val   F1: 0.6142\n",
      "Epoch 96:\n",
      "  Train Loss: 0.4953 | Train Acc: 0.9530 | Train F1: 0.9527\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6210\n",
      "Epoch 97:\n",
      "  Train Loss: 0.4891 | Train Acc: 0.9559 | Train F1: 0.9555\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6290\n",
      "Epoch 98:\n",
      "  Train Loss: 0.4847 | Train Acc: 0.9607 | Train F1: 0.9604\n",
      "  Val   Loss: nan | Val   Acc: 0.6233 | Val   F1: 0.6181\n",
      "Epoch 99:\n",
      "  Train Loss: 0.4796 | Train Acc: 0.9664 | Train F1: 0.9662\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6421\n",
      "Epoch 100:\n",
      "  Train Loss: 0.4754 | Train Acc: 0.9664 | Train F1: 0.9663\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6256\n",
      "Epoch 101:\n",
      "  Train Loss: 0.4686 | Train Acc: 0.9684 | Train F1: 0.9681\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6285\n",
      "Epoch 102:\n",
      "  Train Loss: 0.4643 | Train Acc: 0.9684 | Train F1: 0.9682\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6213\n",
      "Epoch 103:\n",
      "  Train Loss: 0.4608 | Train Acc: 0.9732 | Train F1: 0.9730\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6262\n",
      "Epoch 104:\n",
      "  Train Loss: 0.4543 | Train Acc: 0.9722 | Train F1: 0.9721\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6281\n",
      "Epoch 105:\n",
      "  Train Loss: 0.4526 | Train Acc: 0.9703 | Train F1: 0.9701\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6204\n",
      "Epoch 106:\n",
      "  Train Loss: 0.4461 | Train Acc: 0.9760 | Train F1: 0.9759\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6438\n",
      "Epoch 107:\n",
      "  Train Loss: 0.4431 | Train Acc: 0.9779 | Train F1: 0.9778\n",
      "  Val   Loss: nan | Val   Acc: 0.6413 | Val   F1: 0.6347\n",
      "Epoch 108:\n",
      "  Train Loss: 0.4407 | Train Acc: 0.9751 | Train F1: 0.9749\n",
      "  Val   Loss: nan | Val   Acc: 0.6547 | Val   F1: 0.6482\n",
      "Epoch 109:\n",
      "  Train Loss: 0.4363 | Train Acc: 0.9779 | Train F1: 0.9778\n",
      "  Val   Loss: nan | Val   Acc: 0.6278 | Val   F1: 0.6219\n",
      "Epoch 110:\n",
      "  Train Loss: 0.4316 | Train Acc: 0.9789 | Train F1: 0.9788\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6279\n",
      "Epoch 111:\n",
      "  Train Loss: 0.4279 | Train Acc: 0.9799 | Train F1: 0.9798\n",
      "  Val   Loss: nan | Val   Acc: 0.6413 | Val   F1: 0.6352\n",
      "Epoch 112:\n",
      "  Train Loss: 0.4244 | Train Acc: 0.9808 | Train F1: 0.9807\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6294\n",
      "Epoch 113:\n",
      "  Train Loss: 0.4205 | Train Acc: 0.9789 | Train F1: 0.9788\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6379\n",
      "Epoch 114:\n",
      "  Train Loss: 0.4176 | Train Acc: 0.9818 | Train F1: 0.9817\n",
      "  Val   Loss: nan | Val   Acc: 0.6368 | Val   F1: 0.6313\n",
      "Epoch 115:\n",
      "  Train Loss: 0.4137 | Train Acc: 0.9799 | Train F1: 0.9798\n",
      "  Val   Loss: nan | Val   Acc: 0.6457 | Val   F1: 0.6388\n",
      "Epoch 116:\n",
      "  Train Loss: 0.4115 | Train Acc: 0.9818 | Train F1: 0.9816\n",
      "  Val   Loss: nan | Val   Acc: 0.6502 | Val   F1: 0.6429\n",
      "Epoch 117:\n",
      "  Train Loss: 0.4078 | Train Acc: 0.9866 | Train F1: 0.9864\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6277\n",
      "Epoch 118:\n",
      "  Train Loss: 0.4050 | Train Acc: 0.9837 | Train F1: 0.9835\n",
      "  Val   Loss: nan | Val   Acc: 0.6323 | Val   F1: 0.6265\n",
      "Early stopping triggered!\n",
      "\n",
      " Grid Search completed!\n",
      "Best Hyperparameters: {'lr': 5e-05, 'weight_decay': 0.0}\n",
      "Best Val F1: 0.6521\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Train model for one epoch\n",
    "def train_one_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for x, mask, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Replace any NaNs in the input with 0\n",
    "        x = torch.nan_to_num(x, nan=0.0)\n",
    "\n",
    "        optimizer.zero_grad()           # Clear gradients\n",
    "        logits = model(x, mask)         # Forward pass\n",
    "\n",
    "        # ===== Check for invalid logits (NaN or Inf) =====\n",
    "        if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "            print(\"⚠️ Problematic batch detected!\")\n",
    "            print(f\"x shape: {x.shape}\")\n",
    "            print(f\"mask sum: {mask.sum(dim=1)}\")  # Number of valid nodes per graph\n",
    "            print(f\"y: {y}\")\n",
    "            print(f\"logits max: {torch.nanmax(logits)}, min: {torch.nanmin(logits)}\")\n",
    "            continue  # Skip this batch\n",
    "\n",
    "        loss = loss_fn(logits, y)       # Compute loss\n",
    "        loss.backward()                 # Backpropagation\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n",
    "        optimizer.step()                # Update weights\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)  # Track total loss\n",
    "\n",
    "        preds = logits.argmax(dim=-1)  # Get predicted classes\n",
    "        all_preds.extend(preds.detach().cpu().tolist())\n",
    "        all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "\n",
    "# Evaluate model on validation/test set\n",
    "def evaluate_one_epoch(model, val_loader, loss_fn, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for x, mask, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x, mask)  # Forward pass\n",
    "            logits = torch.clamp(logits, min=-10, max=10)  # Clip to prevent instability\n",
    "\n",
    "            if torch.isnan(logits).any() or torch.isinf(logits).any():\n",
    "                continue  # Skip bad batches during validation\n",
    "\n",
    "            loss = loss_fn(logits, y)\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "\n",
    "# Simple early stopping implementation based on validation F1\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last improvement.\n",
    "            verbose (bool): Whether to print messages.\n",
    "            delta (float): Minimum improvement to reset patience.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_f1 = -float('inf')\n",
    "\n",
    "    def __call__(self, val_f1, model):\n",
    "        score = val_f1\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_f1 = val_f1\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.best_f1 = val_f1\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f599e2-02ca-446c-918a-e4315c6c0956",
   "metadata": {},
   "source": [
    "### Step 5 Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e27c15ed-2e65-4136-a83d-7c7ceccebb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Accuracy: 0.5938\n",
      " Test Macro-F1: 0.5902\n",
      "Confusion Matrix:\n",
      "[[43  3  7  4]\n",
      " [12 25 11  8]\n",
      " [ 9  4 31  9]\n",
      " [18  2  4 34]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# 1. Load the best saved model\n",
    "model.load_state_dict(torch.load(\"../checkpoints/best_model.pt\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# 2. Evaluate on the Test Set\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for x, mask, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x, mask)            # Get model predictions (logits)\n",
    "        preds = logits.argmax(dim=-1)      # Convert logits to predicted class indices\n",
    "\n",
    "        all_preds.extend(preds.cpu().tolist())  # Collect predictions\n",
    "        all_labels.extend(y.cpu().tolist())     # Collect ground truth labels\n",
    "\n",
    "# 3. Compute accuracy and macro F1-score\n",
    "test_acc = accuracy_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(f\" Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\" Test Macro-F1: {test_f1:.4f}\")\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "env_214"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
